{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DNP1mqMWHVU"
   },
   "source": [
    "### TASK 1\n",
    "Classifier for **notMNIST**: This dataset contains images of **alphabets A to J** in various fonts. Your task is to build a classifier for this dataset using CNN.\n",
    ">- Classify each image into one of 10 classes\n",
    ">- Show the effect of permuting the image pixels on CNN classifiers,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWnpR4C6WrJV"
   },
   "source": [
    "\n",
    "\n",
    "### About the Dataset\n",
    "\n",
    "The notMNIST dataset is a collection of images containing the letters **A to J** in various fonts and styles. Each image is **28x28 pixels** and grayscale, which means the pixel intensity ranges from 0 (black) to 255 (white).  \n",
    "\n",
    "The dataset is designed to be a bit like the MNIST digit dataset, but instead of digits, we have **alphabet letters**.\n",
    "\n",
    "A few things to note about this dataset:  \n",
    "- **10 classes** corresponding to letters A-J.  \n",
    "- Images vary in font, size, and style.\n",
    "\n",
    "The notMNIST dataset comes **pre-split** into a **training set** and a **test set**:  \n",
    "\n",
    "- **Training set:** ~15K rows  \n",
    "- **Test set:** ~ 3.75 K rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305,
     "referenced_widgets": [
      "354aee74343f4742861874e5cea2ac03",
      "bdf39e85152946ab85daf3acb6b46061",
      "1d15504f23824f4fbfc334f06c77db3a",
      "5a0b433be8124df392cb74311aa92a22",
      "d73eb283acad406481480e74a28b200a",
      "10a13c8c74484e78b0597f1b69b1dfdc",
      "767fc195f31648b19f898804e3145742",
      "ed9fcc628d4f403e82d6edfcf2c28c9c",
      "4ec835c7f7bb41e29b6c2d67eb998075",
      "153e453fd1414cc5a200f8003b8f87b3",
      "8170a11c7d5f4bdcbe2e5f4adb79e3bf",
      "df78c08be6484d058f061b227181bcba",
      "5dbd3b1fedde4578b1d25218fc28bf51",
      "c2fe92882b6943a98a7b7b41d7ff5a3a",
      "aa2bc1a408b04666a8eeb0fb88ab1dc9",
      "77d18490b8d14beb9e7ed1bbf3da1f1f",
      "3f4eebb618484156ac985ce918954d8d",
      "e1de68e33a5e4654a3e54ab71f5ee6e2",
      "65d4c1b458fc4b3f875c6a994db3b0d6",
      "31574df77c844f5e9288540225dfc6b4",
      "a4318042df114b31b3dff4ac09d6d0db",
      "7e4afe6e1a204199953f76bf0e43a070",
      "5a9389827bc14caf8612f13e56257472",
      "de4e5d44805946759270349610aad58d",
      "81a55315b97549249e1e4a34465266ad",
      "e004c83548624223be89894c6547e254",
      "26cda11f73b947cf987890c5b66c080b",
      "bb61960770c045228f38e26375b77625",
      "9414b7d0b7ac4161b986bbf90dbbaff6",
      "ab33b0511f7a4835bc868f4da93fc6d0",
      "50abb0346222425c9a62d5cea20122f6",
      "fea5ff743dd74cfa881401e652546b4c",
      "1a56f55dafc74f698f1c0d17ede0b9fa",
      "137e9e1b01aa403a9bbb259dd4470e28",
      "b7631eae320043808c908805225bbf24",
      "b22e462242cd49269225a01afb0b42ed",
      "09127007d04b4200870c7295078e191f",
      "97b484ec52fb468d877cfcfaf24ff79b",
      "4cb3b8e6b48e4a14b26eb60dae530346",
      "f7203cb29c5b4eb7a75a91c7f64cee71",
      "db8180e127b2428da4a55e4aa57a513e",
      "03a58375847c46ac9ba013735f932ddc",
      "bba6c2e83d1f444b975f569cdae2aed6",
      "4c5c943f8b844c5984bb842332e32503",
      "bf1ec3548aff44cf98ac2eab4007fa8b",
      "b574c836da1a4076bce882ff68302f95",
      "80c073d65fd14bb889655b2dff25a072",
      "0689cec3daa64f029b6b3fec7beb2ea4",
      "73d5b809ddc84439ade575530f174c89",
      "f4c0d315014d4685913ede783d8292a0",
      "edd51c6313124fb2a2ff102c9dc31ae9",
      "17253c032025452eb67879505994ed2d",
      "ad5c27e077bd47acbfcd75b5bb7403b8",
      "6889e08d366a42f2a8a8fe274890c9d7",
      "a0bdea0c1e4a4090a29ec082851b7aef"
     ]
    },
    "id": "dEfrA42V-J1d",
    "outputId": "904172a5-9ad9-4f81-bd8c-7fde5dde614b"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"anubhavmaity/notMNIST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRD0ykNxf4Mu"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Before we start building our CNN, we first import the necessary libraries.\n",
    "\n",
    "We also set **random seeds** for PyTorch, NumPy, and Python's built-in random module. This ensures that our experiments are **reproducible** — if we run the notebook again, we get the same results.  \n",
    "\n",
    "Finally, we define the **device** (GPU if available, otherwise CPU) so that our model can train efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JrwwB-8N-SiF",
    "outputId": "9db2ae77-4d0c-47a5-e278-3809c67dee08"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy, random\n",
    "\n",
    "\n",
    "# set the PseudoRandom Generator Seeds for reproducibility\n",
    "torch.manual_seed(99)\n",
    "random.seed(99)\n",
    "numpy.random.seed(99)\n",
    "\n",
    "\n",
    "# this 'device' will be used for training our model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soi3a006oID0"
   },
   "source": [
    "### Raw Dataset Example\n",
    "\n",
    "A sample from the HuggingFace notMNIST training set looks like this:\n",
    "\n",
    "- `image`: a PIL grayscale image of size 28x28 (`mode=L`)  \n",
    "- `label`: an integer from 0 to 9 (here 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nITA9e5LnxKu",
    "outputId": "cc2c9964-f023-42a2-f295-0cbfdb76cb8e"
   },
   "outputs": [],
   "source": [
    "print(ds['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuceEXLqgPzs"
   },
   "source": [
    "### Loading and Preprocessing the Dataset\n",
    "\n",
    "The notMNIST dataset already comes split into **training** and **test** sets.\n",
    "\n",
    "Since our CNN works best with **tensor inputs**, we transform the images into PyTorch tensors and normalize them. Normalization scales the pixel values to roughly **[-1, 1]**, which helps the network train faster and more stably.  \n",
    "\n",
    "We also define a **collate function** for our DataLoader, which organizes a batch of images and labels into tensors suitable for training — similar to how we handle the MNIST dataset.  \n",
    "\n",
    "Finally, we create **DataLoaders** for both training and test sets. The training loader shuffles the data to prevent the model from learning the order of the images, while the test loader keeps the order fixed for consistent evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFLmz0o7-iRA"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Apply transform inside HF dataset\n",
    "def transform_examples(batch):\n",
    "    batch[\"image\"] = [transform(img) for img in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "ds.set_transform(transform_examples)\n",
    "\n",
    "# Define collate function to make batches like MNIST\n",
    "def collate_fn(batch):\n",
    "    images = torch.stack([item[\"image\"] for item in batch])\n",
    "    labels = torch.tensor([item[\"label\"] for item in batch])\n",
    "    return images, labels\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(ds[\"train\"], batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(ds[\"test\"],  batch_size=1000, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvXksuIumxvE"
   },
   "source": [
    "### Displaying Sample Training Images\n",
    "\n",
    "We take a batch of images from the DataLoader and show the first 20.\n",
    "Each image is grayscale, and its label is displayed on top.\n",
    "This gives a quick visual check of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "3qJ67k-RDs7u",
    "outputId": "cf095c43-d80d-4433-e7b1-cf0cb32fb9e1"
   },
   "outputs": [],
   "source": [
    "# show some training images\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "# fetch a batch of train images\n",
    "image_batch, label_batch = next(iter(train_loader))\n",
    "\n",
    "for i in range(20):\n",
    "    image = image_batch[i]\n",
    "    label = label_batch[i].item()\n",
    "    plt.subplot(2, 10, i + 1)\n",
    "    #image, label = train_loader.dataset.__getitem__(i)\n",
    "    plt.imshow(image.squeeze().numpy(),cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_aB77mdopLzf"
   },
   "source": [
    "### Exploratory Data Analysis (EDA) after Preprocessing\n",
    "\n",
    "1. **Class Distribution:**  \n",
    "   The class more or less seem to be balanced, where each class have roughly same number of training samples.\n",
    "\n",
    "2. **Image Shape and Type:**  \n",
    "   Each image has been converted to a PyTorch tensor of shape `[1, 28, 28]` (channels x height x width), which is the format expected by the CNN.\n",
    "\n",
    "3. **Pixel Value Range:**  \n",
    "   After normalization, pixel values lie between -1 and 1. This ensures stable training and faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "pjgGf2WJnBbO",
    "outputId": "d3ac1007-3774-4271-f01b-e40a554954f6"
   },
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "labels = [item['label'] for item in ds['train']]\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(labels, bins=range(11), edgecolor='black', align='left')\n",
    "plt.xticks(range(10))\n",
    "plt.xlabel(\"Class (A=0, B=1, ... J=9)\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.title(\"Class Distribution in Training Set\")\n",
    "plt.show()\n",
    "\n",
    "# Check image shape and type\n",
    "print(\"Example image shape:\", ds['train'][0]['image'].size)\n",
    "print(\"Example image type:\", type(ds['train'][0]['image']))\n",
    "\n",
    "# Pixel value range in a batch\n",
    "image_batch, label_batch = next(iter(train_loader))\n",
    "print(\"Batch pixel min:\", image_batch.min().item())\n",
    "print(\"Batch pixel max:\", image_batch.max().item())\n",
    "print(\"Batch pixel mean:\", image_batch.mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NewvJNPXpis2",
    "outputId": "ebb89e84-7c5e-4b9d-cea5-ae3edb941709"
   },
   "outputs": [],
   "source": [
    "print(f\"Length of trainining samples:{ds['train'].shape}\")\n",
    "print(f\"Length of trainining samples:{ds['test'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_BdQODIqrRv"
   },
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIti3UM8mel9"
   },
   "source": [
    "### Training and Evaluation Functions\n",
    "\n",
    "- **get_n_params(model)**: Computes the total number of trainable parameters in the model.\n",
    "\n",
    "- **train(epoch, model)**: Trains the given model for one epoch. Performs forward pass, computes loss, backpropagates gradients, updates weights, and records training accuracy for the epoch.\n",
    "\n",
    "- **test(model)**: Evaluates the model on the test set. Computes total loss and accuracy, and stores test accuracy for tracking over epochs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywkBnZElL_8E"
   },
   "outputs": [],
   "source": [
    "# function to count number of parameters\n",
    "def get_n_params(model):\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.nelement()\n",
    "    return np\n",
    "\n",
    "accuracy_list = []\n",
    "train_accuracy_list = []\n",
    "# we pass a model object to this trainer, and it trains this model for one epoch\n",
    "def train(epoch, model):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # clear old gradients\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # compute loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        # add loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "        # compute batch accuracy\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "        total += target.size(0)\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "      # average loss & accuracy over epoch\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_accuracy = 100. * correct / total\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "\n",
    "    #print('Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    #train_loss, correct, total, train_accuracy))\n",
    "\n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)   # send to device\n",
    "        output = model(data)\n",
    "        # compute loss\n",
    "        test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        # number of correct predictions\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVk9wjjXmOsE"
   },
   "source": [
    "### CNN Architecture for notMNIST\n",
    "\n",
    "- **Conv1 (3x3 kernel, 32 channels):**  \n",
    "  We start with a small kernel to pick up **basic features** like edges and corners. 32 channels let the network learn multiple patterns at this level.  \n",
    "\n",
    "- **Conv2 (3x3 kernel, 64 channels):**  \n",
    "  Going a bit deeper, this layer combines the low-level features to detect **more complex shapes**. BatchNorm keeps training stable and speeds things up.  \n",
    "\n",
    "- **Conv3 (5x5 kernel, 128 channels):**  \n",
    "  More channels can generate richer feature maps.\n",
    "\n",
    "- **Fully Connected Layer ($128*4*4$ -> 128):**  \n",
    "  After the pooling layers, the feature maps are flattened and condensed to 128 neurons to get a **compact representation** of the important features.  \n",
    "\n",
    "- **Dropout (0.6):**  \n",
    "  Randomly turns off neurons during training to **prevent overfitting**.  \n",
    "\n",
    "- **Output Layer (128 -> 10):**  \n",
    "  Finally, we map the features to the **10 classes (A-J)**.  \n",
    "\n",
    "- **Why more channels?**  \n",
    "  notMNIST has letters in **different fonts and styles**, so more channels help the CNN learn **richer and more varied patterns**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPHttMJXMC-f"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3,padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3,padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5,padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(128*4*4, 128)\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5A6IRSuDrK3N"
   },
   "source": [
    "### Training Setup for CNN on notMNIST\n",
    "\n",
    "- **Input size:** 28x28 pixels  \n",
    "- **Output size:** 10 classes (letters A–J).  \n",
    " - **Optimizer:** Stochastic Gradient Descent (SGD) with learning rate 0.01 and momentum 0.5 to speed up convergence.  \n",
    "- **Training loop:** We train for 10 epochs, computing loss and updating weights with backpropagation each batch, and check performance on the test set after every epoch.  \n",
    "- **Number of parameters:** Prints the total trainable parameters so we know the model size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BPGXN2tfM0LF",
    "outputId": "e5aa09b2-51c7-4898-c31d-135993c55f4b"
   },
   "outputs": [],
   "source": [
    "input_size  = 28*28   # images are 28x28 pixels\n",
    "output_size = 10      # there are 10 classes\n",
    "print(\"Training on \", device)\n",
    "model_cnn = CNN(input_size, output_size)\n",
    "model_cnn.to(device)\n",
    "optimizer = optim.SGD(model_cnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
    "\n",
    "for epoch in range(0, 10):\n",
    "    train(epoch, model_cnn)\n",
    "    test(model_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8hw2F9tlVYT"
   },
   "source": [
    "### Observations\n",
    "\n",
    "We see from the plot that train and test accuracy generally increase over the epochs, with occasional dips. These dips occur due to stochastic gradient updates and regularization effects (like dropout), which can temporarily reduce accuracy. Despite these fluctuations, the overall trend shows that the model is learning and improving its performance on both training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "tmy2ougk01yf",
    "outputId": "4c7b0f08-83db-42e0-e755-2a9205682b98"
   },
   "outputs": [],
   "source": [
    "epochs = range(10)  # 10 epochs\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(epochs, accuracy_list[-10:], marker='o', color='blue')\n",
    "plt.plot(epochs, train_accuracy_list[-10:], marker='s', color='green', label='Train Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.title('Train vs Test Accuracy over 10 epochs')\n",
    "plt.xticks(epochs)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HowIwkGeN8pF"
   },
   "outputs": [],
   "source": [
    "# Function for viewing an image and it's predicted classes.\n",
    "def visualize_pred(img, pred_prob, real_label):\n",
    "    #pred_prob = pred_prob.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    pred_label = numpy.argmax(pred_prob)\n",
    "    ax1.set_title([real_label, pred_label])\n",
    "\n",
    "    ax2.barh(numpy.arange(10), pred_prob)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(numpy.arange(10))\n",
    "    ax2.set_yticklabels(numpy.arange(10))\n",
    "    ax2.set_title('Prediction Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_OXAMmlnObg"
   },
   "source": [
    "### Prediction Visualization\n",
    "\n",
    "We can see from the plots that the CNN is assigning **high probabilities to the correct classes** for most images.  \n",
    "This indicates that the network has learned meaningful features and is confident in its predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NmEq8I4HOBby",
    "outputId": "7e08370f-ec85-4b1b-d3a6-b11e47901a96"
   },
   "outputs": [],
   "source": [
    "model_cnn.to('cpu')\n",
    "\n",
    "# fetch a batch of test images\n",
    "image_batch, label_batch = next(iter(test_loader))\n",
    "\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    log_pred_prob_batch = model_cnn(image_batch)\n",
    "for i in range(10):\n",
    "    img = image_batch[i]\n",
    "    real_label = label_batch[i].item()\n",
    "    log_pred_prob = log_pred_prob_batch[i]\n",
    "    # Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "    pred_prob = torch.exp(log_pred_prob).data.numpy().squeeze()\n",
    "    visualize_pred(img, pred_prob, real_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zz7iZqcry5Kc"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgxmDLn9qxWN"
   },
   "source": [
    "### Effect of permuting the image pixels on CNN classifiers\n",
    "\n",
    "\n",
    "- Each 28x28 image is flattened to a 784-length vector.  \n",
    "- A **fixed random permutation** is applied to the pixels, scrambling them in the same way for all images.  \n",
    "- The permuted vector is reshaped back to 28x28 for visualization.  \n",
    "- Left column: original images; right column: permuted images.  \n",
    "- This visually demonstrates how scrambling pixels destroys spatial structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "id": "6Uufp2IVSsyp",
    "outputId": "aded875c-b576-4472-e336-eea3f0b0c445"
   },
   "outputs": [],
   "source": [
    "fixed_perm = torch.randperm(784) # Fix a permutation of the image pixels; We apply the same permutation to all images\n",
    "\n",
    "# show some training images\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# fetch a batch of train images; RANDOM\n",
    "image_batch, label_batch = next(iter(train_loader))\n",
    "\n",
    "for i in range(6):\n",
    "    image = image_batch[i]\n",
    "    image_perm = image.view(-1, 28*28).clone()\n",
    "    image_perm = image_perm[:, fixed_perm]\n",
    "    image_perm = image_perm.view(-1, 1, 28, 28)\n",
    "\n",
    "    label = label_batch[i].item()\n",
    "    plt.subplot(3,4 , 2*i + 1)\n",
    "    #image, label = train_loader.dataset.__getitem__(i)\n",
    "    plt.imshow(image.squeeze().numpy())\n",
    "    plt.axis('off')\n",
    "    plt.title(label)\n",
    "    plt.subplot(3, 4, 2*i+2)\n",
    "    plt.imshow(image_perm.squeeze().numpy())\n",
    "    plt.axis('off')\n",
    "    plt.title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T49OcnQbs75k"
   },
   "source": [
    "- `scramble_train` performs one epoch of training on these permuted images using the labels.  \n",
    "- `scramble_test` evaluates the CNN on permuted test images and computes accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DyjGHUk2TT0a"
   },
   "outputs": [],
   "source": [
    "accuracy_list_s = []\n",
    "train_accuracy_list_s = []\n",
    "def scramble_train(epoch, model, perm=torch.arange(0, 784).long()):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # permute pixels\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # compute batch accuracy\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "        total += target.size(0)\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    # compute epoch accuracy\n",
    "    train_accuracy = 100. * correct / total\n",
    "    train_accuracy_list_s.append(train_accuracy)\n",
    "\n",
    "def scramble_test(model, perm=torch.arange(0, 784).long()):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # permute pixels\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    accuracy_list_s.append(accuracy)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdQIyvoFw2_9"
   },
   "source": [
    "### Training CNN on Permuted Images\n",
    "\n",
    "- We train the same CNN architecture, but **all image pixels are permuted** in a fixed random order (`fixed_perm`).  \n",
    "- This simulates a scenario where **spatial structure is destroyed**, testing how the CNN performs when it can’t rely on normal 2D patterns.  \n",
    "- Training uses **SGD with learning rate 0.01 and momentum 0.5**, for 10 epochs.  \n",
    "- After each epoch, we evaluate the model on the **similarly permuted test set**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GZf_H2GKTg99",
    "outputId": "b160fa37-3d57-415a-f502-9a8e2fd85479"
   },
   "outputs": [],
   "source": [
    "print(\"Training on \", device)\n",
    "model_cnn_3 = CNN(input_size, output_size)\n",
    "model_cnn_3.to(device)\n",
    "optimizer = optim.SGD(model_cnn_3.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn_3)))\n",
    "\n",
    "for epoch in range(0, 10):\n",
    "    scramble_train(epoch, model_cnn_3, fixed_perm)\n",
    "    scramble_test(model_cnn_3, fixed_perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MB3gcUMZyel-"
   },
   "source": [
    "### Effect of Pixel Permutation on Accuracy\n",
    "\n",
    "After training the CNN on **permuted images**, we observe that the test accuracy dropped slightly from ~94% (on normal images) to **92%**.  \n",
    "\n",
    "Even though the spatial structure of the images is destroyed, the network still achieves high accuracy.\n",
    "This is because pixels in every image are permuted the same way.\n",
    "This shows that the CNN is able to **adapt and learn useful patterns** even from scrambled pixel arrangements, though it slightly loses some precision compared to the original images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "umvA3XEvx1G3",
    "outputId": "1e36776a-6184-49c1-f055-dcbcd9111ba5"
   },
   "outputs": [],
   "source": [
    "epochs = range(10)  # 10 epochs\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(epochs, accuracy_list_s[-10:], marker='o', color='blue')\n",
    "plt.plot(epochs, train_accuracy_list_s[-10:], marker='s', color='green', label='Train Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.title('Train vs Test Accuracy over 10 epochs')\n",
    "plt.xticks(epochs)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPDjtnG8ysZd"
   },
   "source": [
    "### Prediction Visualization\n",
    "\n",
    "We can see from the plots that the CNN is assigning **high probabilities to the correct classes** for most images. Though some minor confusions are observed for some other classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FganqSNtTjFe",
    "outputId": "ad1220a9-66e2-432f-cefa-079823a44bb6"
   },
   "outputs": [],
   "source": [
    "model_cnn_3.to('cpu')\n",
    "\n",
    "# fetch a batch of test images\n",
    "image_batch, label_batch = next(iter(test_loader))\n",
    "image_batch_scramble = image_batch.view(-1, 28*28)\n",
    "image_batch_scramble = image_batch_scramble[:, fixed_perm]\n",
    "image_batch_scramble = image_batch_scramble.view(-1, 1, 28, 28)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    log_pred_prob_batch = model_cnn_3(image_batch_scramble)\n",
    "for i in range(10):\n",
    "    img = image_batch[i]\n",
    "    img_perm = image_batch_scramble[i]\n",
    "    real_label = label_batch[i].item()\n",
    "    log_pred_prob = log_pred_prob_batch[i]\n",
    "    # Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "    pred_prob = torch.exp(log_pred_prob).data.numpy().squeeze()\n",
    "    visualize_pred(img_perm, pred_prob, real_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQUn2ULYUq8N"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
