{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "de81ddca-ef6d-46eb-8d82-fb9051d1603b",
      "metadata": {
        "id": "de81ddca-ef6d-46eb-8d82-fb9051d1603b"
      },
      "source": [
        "### Name: Riya Shyam Huddar\n",
        "### Roll no: MDS202431\n",
        "### NLP Assignment 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca83ceb-d070-4432-bf32-4969b6eb8250",
      "metadata": {
        "id": "dca83ceb-d070-4432-bf32-4969b6eb8250"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing\n",
        "import time\n",
        "import os\n",
        "import psutil\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "from collections import defaultdict\n",
        "import stopwordsiso as stopwords\n",
        "from numpy.linalg import svd\n",
        "from numpy.linalg import norm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b62b864-1797-42e7-a81d-86066896c3bd",
      "metadata": {
        "id": "1b62b864-1797-42e7-a81d-86066896c3bd",
        "outputId": "952f90cf-47ea-4cb6-97d0-f5028556ba0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stopwordsiso in d:\\soft\\anaconda\\lib\\site-packages (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install stopwordsiso"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dc56928-39cf-43ec-b9fe-a84663a6ed90",
      "metadata": {
        "id": "4dc56928-39cf-43ec-b9fe-a84663a6ed90"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "312895cb-8b5f-4c45-850e-35652e33b91c",
      "metadata": {
        "id": "312895cb-8b5f-4c45-850e-35652e33b91c"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06a4ada0-eda7-401e-8201-9251f6039264",
      "metadata": {
        "id": "06a4ada0-eda7-401e-8201-9251f6039264"
      },
      "source": [
        "Firstly, it's important to understand the computational resources available. This helps us decide:\n",
        "- The vocabulary size we can handle.\n",
        "- Appropriate usage of parallel processing\n",
        "- Memory considerations for storing large co-occurrence matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7224878-8b00-4b64-bd4e-9e6603661666",
      "metadata": {
        "id": "b7224878-8b00-4b64-bd4e-9e6603661666",
        "outputId": "3f8552c6-3920-4361-c774-76c6be2753c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of CPU cores: 12\n",
            "CPU Speed: 1.30 GHz\n",
            "Memory: 16.88 GB\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of CPU cores: {os.cpu_count()}\")\n",
        "\n",
        "# CPU speed is reported in MHz, convert to GHz\n",
        "cpu_freq = psutil.cpu_freq()\n",
        "print(f\"CPU Speed: {cpu_freq.max / 1000:.2f} GHz\")\n",
        "\n",
        "# Memory is in bytes, convert to GB\n",
        "print(f\"Memory: {psutil.virtual_memory().total / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1138f97-9105-40f0-8921-5ce265c383fe",
      "metadata": {
        "id": "b1138f97-9105-40f0-8921-5ce265c383fe"
      },
      "source": [
        "### Cleaning the Marathi Corpus\n",
        "\n",
        "For this assignment, we are using the **Marathi** corpus.  \n",
        "\n",
        "The corpus being used was already cleaned in **Assignment 1**, but to ensure accuracy for this analysis, we perform additional cleaning:\n",
        "\n",
        "1. **Script-specific numbers**: Marathi uses Devanagari digits (०-९), which we remove to avoid noise in the embeddings.\n",
        "2. **ASCII digits**: Standard 0–9 digits are removed.\n",
        "3. **Punctuation**: Both ASCII punctuation and Marathi-specific punctuation marks (`।`, `॥`, quotation marks, dashes, etc.) are removed.\n",
        "4. **Token validation**: Only tokens containing at least one Devanagari character are retained, and tokens that are purely numeric are discarded.\n",
        "\n",
        "This ensures that the corpus used for co-occurrence matrix computation contains **valid Marathi words**, improving the quality of both sparse and dense embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9a87352-3770-43e6-a94d-84971f239447",
      "metadata": {
        "id": "a9a87352-3770-43e6-a94d-84971f239447"
      },
      "outputs": [],
      "source": [
        "# Clean Marathi corpus to remove punctuations and numbers\n",
        "def clean_marathi_corpus(input_path, output_path):\n",
        "    # Define punctuation to remove (ASCII + Marathi-specific)\n",
        "    all_punct = string.punctuation + \"।॥“”‘’—–\"\n",
        "\n",
        "    # Define Devanagari digits (०-९) and ASCII digits (0-9)\n",
        "    all_digits = \"०१२३४५६७८९\" + string.digits\n",
        "\n",
        "    # Check if valid Marathi token (Devanagari letters only, no digits)\n",
        "    def is_valid_token_mr(token):\n",
        "        # Must contain at least one Devanagari char, and not be pure digits\n",
        "        return bool(re.search(r'[\\u0900-\\u097F]', token)) and not re.fullmatch(r'[\\d०-९]+', token)\n",
        "\n",
        "    word_counts = Counter()\n",
        "\n",
        "    with open(input_path, 'r', encoding='utf-8') as f_in, \\\n",
        "         open(output_path, 'w', encoding='utf-8') as f_out:\n",
        "\n",
        "        for line in f_in:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            tokens = line.split()\n",
        "\n",
        "            # Remove punctuation and digits\n",
        "            cleaned_tokens = [\n",
        "                t.translate(str.maketrans('', '', all_punct + all_digits))\n",
        "                for t in tokens\n",
        "            ]\n",
        "\n",
        "            # Keep only valid tokens\n",
        "            cleaned_tokens = [t for t in cleaned_tokens if is_valid_token_mr(t)]\n",
        "\n",
        "            # Update word counts\n",
        "            word_counts.update(cleaned_tokens)\n",
        "\n",
        "            if cleaned_tokens:\n",
        "                f_out.write(\" \".join(cleaned_tokens) + \"\\n\")\n",
        "\n",
        "    print(f\"Fully cleaned Marathi corpus saved to: {output_path}\")\n",
        "    print(f\"Total unique words in cleaned corpus: {len(word_counts)}\")\n",
        "    print(\"Top 20 words:\", word_counts.most_common(20))\n",
        "\n",
        "    return word_counts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98375294-ff3f-450d-89b6-df57d15a920c",
      "metadata": {
        "id": "98375294-ff3f-450d-89b6-df57d15a920c"
      },
      "source": [
        "We save the updated clean corpus on local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd234520-8055-4179-a839-608f06f6b6e9",
      "metadata": {
        "id": "dd234520-8055-4179-a839-608f06f6b6e9",
        "outputId": "d2d62392-fc26-4299-d21e-786f1e864691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fully cleaned Marathi corpus saved to: D:/CMI/NLP/mrwiki_corpus_cleaned_updated.txt\n",
            "Total unique words in cleaned corpus: 718524\n",
            "Top 20 words: [('आणि', 261635), ('आहे', 261499), ('या', 149215), ('हे', 137602), ('व', 117368), ('एक', 101263), ('ते', 95927), ('हा', 88186), ('पुनर्निर्देशन', 77186), ('होते', 65949), ('मध्ये', 64461), ('आहेत', 64430), ('केले', 61389), ('ही', 59843), ('येथे', 58718), ('जिल्ह्यातील', 53862), ('इस', 50062), ('तालुक्यातील', 49517), ('गावे', 49275), ('केली', 48595)]\n"
          ]
        }
      ],
      "source": [
        "# Clean the Marathi corpus and save the updated version\n",
        "input_path = \"D:/CMI/NLP/mrwiki_corpus_cleaned.txt\"\n",
        "output_path = \"D:/CMI/NLP/mrwiki_corpus_cleaned_updated.txt\"\n",
        "\n",
        "word_counts = clean_marathi_corpus(input_path, output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e11b38d5-bdd9-42b0-a896-2670068cdb53",
      "metadata": {
        "id": "e11b38d5-bdd9-42b0-a896-2670068cdb53"
      },
      "outputs": [],
      "source": [
        "# Helper function to count vocabulary and tokens from a file\n",
        "def vocab_token_count(file_path):\n",
        "    # Read the file\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        words = f.read().split()  # split by whitespace\n",
        "\n",
        "    # Count tokens and vocab\n",
        "    num_tokens = len(words)\n",
        "    vocab = set(words)\n",
        "    num_vocab = len(vocab)\n",
        "    return num_tokens,num_vocab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e599cf6-52de-46dc-aa49-9048e88a8069",
      "metadata": {
        "id": "9e599cf6-52de-46dc-aa49-9048e88a8069"
      },
      "source": [
        "The cleaned Marathi corpus contains **15,091,613 tokens**, and the vocabulary size is **718,524**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0a3dc17-9c88-4bdc-9015-4ad98cbc54e8",
      "metadata": {
        "id": "c0a3dc17-9c88-4bdc-9015-4ad98cbc54e8",
        "outputId": "16ad73f7-15de-404d-8322-985cf667f88c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tokens: 15091613\n",
            "Vocabulary size: 718524\n"
          ]
        }
      ],
      "source": [
        "num_tokens,num_vocab=vocab_token_count(output_path)\n",
        "\n",
        "# Print results\n",
        "print(f\"Number of tokens: {num_tokens}\")\n",
        "print(f\"Vocabulary size: {num_vocab}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ad2f81a-b39a-4232-a2c1-8daf2f9f1bf5",
      "metadata": {
        "id": "7ad2f81a-b39a-4232-a2c1-8daf2f9f1bf5"
      },
      "outputs": [],
      "source": [
        "# Reads a cleaned corpus file and returns a list of all tokens.\n",
        "def create_tokens_var(path):\n",
        "    tokens = []\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line_tokens = line.strip().split()  # whitespace tokenization\n",
        "            tokens.extend(line_tokens)\n",
        "    print(f\"Number of tokens in cleaned corpus: {len(tokens)}\")\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17d5b525-38fa-4c59-92f5-c53b551ad7e5",
      "metadata": {
        "id": "17d5b525-38fa-4c59-92f5-c53b551ad7e5",
        "outputId": "cf33ea7f-415f-421e-aa15-c2db832e3106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tokens in cleaned corpus: 15091613\n"
          ]
        }
      ],
      "source": [
        "tokens=create_tokens_var(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afeda564-2861-48b7-b187-8e9d7348d670",
      "metadata": {
        "id": "afeda564-2861-48b7-b187-8e9d7348d670"
      },
      "source": [
        "### Removing Marathi Stopwords\n",
        "\n",
        "To further refine the corpus, we remove **common Marathi stopwords**.  \n",
        "\n",
        "Stopwords are frequent words (like 'अधिक' (more), 'अनेक' (many), 'अशी' (such), 'असलयाचे' (to be)) that usually do not contribute meaningful semantic information for word embeddings. Removing them helps:\n",
        "\n",
        ">1. Reduce noise in the co-occurrence matrix and improve the quality of the corpus.  \n",
        ">2. Lower memory requirements since the vocabulary is slightly reduced.\n",
        "\n",
        "**Note:** The inflectional richness of Marathi (for example, 'असलयाचे' (to be), 'असलेल्या' (that existed), 'असा' (such), 'असून' (being)) poses challenges for stemming and lemmatization. Due to these language-specific characteristics, accurate morphological processing is complicated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44ed1975-f954-4be1-9529-086a61d11e3a",
      "metadata": {
        "id": "44ed1975-f954-4be1-9529-086a61d11e3a",
        "outputId": "d9ac3cf6-1ab9-4c77-dc2c-156790b7ae88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 50 Marathi stopwords:\n",
            "['अधिक', 'अनेक', 'अशी', 'असलयाचे', 'असलेल्या', 'असा', 'असून', 'असे', 'आज', 'आणि', 'आता', 'आपल्या', 'आला', 'आली', 'आले', 'आहे', 'आहेत', 'एक', 'एका', 'कमी', 'करणयात', 'करून', 'का', 'काम', 'काय', 'काही', 'किवा', 'की', 'केला', 'केली', 'केले', 'कोटी', 'गेल्या', 'घेऊन', 'जात', 'झाला', 'झाली', 'झाले', 'झालेल्या', 'टा', 'डॉ', 'तर', 'तरी', 'तसेच', 'ता', 'ती', 'तीन', 'ते', 'तो', 'त्या']\n",
            "Total number of Marathi stopwords: 99\n"
          ]
        }
      ],
      "source": [
        "# Load Marathi stopwords\n",
        "marathi_stopwords = stopwords.stopwords(\"mr\")\n",
        "\n",
        "# Convert to a sorted list\n",
        "marathi_stopwords_list = sorted(list(marathi_stopwords))\n",
        "\n",
        "# Print the first 50 stopwords\n",
        "print(\"First 50 Marathi stopwords:\")\n",
        "print(marathi_stopwords_list[:50])\n",
        "\n",
        "# Print total number of stopwords\n",
        "print(f\"Total number of Marathi stopwords: {len(marathi_stopwords_list)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c401681-da4e-4fdc-ab50-5f3ee8ea8831",
      "metadata": {
        "id": "1c401681-da4e-4fdc-ab50-5f3ee8ea8831"
      },
      "outputs": [],
      "source": [
        "# Remove stopwords from the list of tokens from the corpus\n",
        "def remove_stopwords(tokens):\n",
        "    filtered_tokens = [t for t in tokens if t not in marathi_stopwords]\n",
        "\n",
        "    # Compute new vocabulary\n",
        "    filtered_vocab = list(set(filtered_tokens))\n",
        "\n",
        "    # Print stats\n",
        "    print(f\"Number of tokens after stopword removal: {len(filtered_tokens)}\")\n",
        "    print(f\"Vocabulary size after stopword removal: {len(filtered_vocab)}\")\n",
        "\n",
        "    # Return filtered tokens and vocab\n",
        "    return filtered_tokens,filtered_vocab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5c63d32-950d-4084-8a83-82cebc00b148",
      "metadata": {
        "id": "a5c63d32-950d-4084-8a83-82cebc00b148"
      },
      "source": [
        "After removing the stopwords the cleaned file has **12,552,691** tokens and the vocabulary size is **718,431**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49934a45-71b5-4cf0-b6d8-02d1673f37d7",
      "metadata": {
        "id": "49934a45-71b5-4cf0-b6d8-02d1673f37d7",
        "outputId": "b8e926c8-4d0b-4c89-ec04-f991801afc1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tokens after stopword removal: 12552691\n",
            "Vocabulary size after stopword removal: 718431\n"
          ]
        }
      ],
      "source": [
        "filtered_tokens,filtered_vocab=remove_stopwords(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc8e2d0f-8888-4bb6-ab04-a941e4812649",
      "metadata": {
        "id": "cc8e2d0f-8888-4bb6-ab04-a941e4812649"
      },
      "outputs": [],
      "source": [
        "with open('D:/CMI/NLP/mrwiki_tokens_stopwords_removed.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(\"\\n\".join(filtered_tokens))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d39bb188-890a-41c0-be55-5cf4e2128f49",
      "metadata": {
        "id": "d39bb188-890a-41c0-be55-5cf4e2128f49",
        "outputId": "24e16c63-f0d7-48de-e4de-1377d63c0192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tokens in cleaned corpus: 12552691\n"
          ]
        }
      ],
      "source": [
        "tokens=create_tokens_var('D:/CMI/NLP/mrwiki_tokens_stopwords_removed.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "383e3d61-8ee1-4fc4-b4eb-1103b58cf4c7",
      "metadata": {
        "id": "383e3d61-8ee1-4fc4-b4eb-1103b58cf4c7"
      },
      "source": [
        "### Selecting Top Vocabulary for Co-occurrence Matrix\n",
        "\n",
        "To build the co-occurrence matrix efficiently, we select the **top `n` most frequent words** from the cleaned corpus.  \n",
        "\n",
        "We initially experimented with a **20,000-word vocabulary**, but computing correlations for this size proved **computationally expensive** due to the high complexity of pairwise correlation calculations.  \n",
        "\n",
        "Therefore, we chose **11,000 words** as a compromise between coverage and computational feasibility.  \n",
        "\n",
        "**Matrix size:** With 11,000 words, the co-occurrence (or correlation) matrix will be **11,000 × 11,000**(~0.5 GB), which is large but manageable on the available system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a19ead4f-bd37-403c-85ff-a72825912122",
      "metadata": {
        "id": "a19ead4f-bd37-403c-85ff-a72825912122"
      },
      "outputs": [],
      "source": [
        "# Returns top 'n' most frequent words from a list of tokens\n",
        "def get_top_n_vocab(tokens, n=11000):\n",
        "\n",
        "    word_counts = Counter(tokens)\n",
        "    top_vocab = [word for word, _ in word_counts.most_common(n)]\n",
        "\n",
        "    print(f\"Selected top {len(top_vocab)} words as vocabulary.\")\n",
        "    return top_vocab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9828adbb-9132-41ed-ac77-32d0fc0b7bd1",
      "metadata": {
        "id": "9828adbb-9132-41ed-ac77-32d0fc0b7bd1",
        "outputId": "40b0b9f8-c539-4d9c-a92c-f4f62814c819"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected top 11000 words as vocabulary.\n"
          ]
        }
      ],
      "source": [
        "top_vocab=get_top_n_vocab(tokens,11000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba5b82b4-f9ff-4a70-8d21-d477600d226c",
      "metadata": {
        "id": "ba5b82b4-f9ff-4a70-8d21-d477600d226c"
      },
      "source": [
        "### Task 1: Load and Prepare Co-occurrence Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52d41bda-5698-4a5a-aac0-9693e3ac828b",
      "metadata": {
        "id": "52d41bda-5698-4a5a-aac0-9693e3ac828b"
      },
      "source": [
        "### Building the Co-occurrence Matrix\n",
        "\n",
        "We build a **co-occurrence matrix** for the top 11,000 vocabulary words using a **sliding window approach** with ramped weights.  \n",
        "\n",
        "- **Window size:** 4 words on each side of the center word.  \n",
        "- **Ramped weights:** Words closer to the center word are weighted higher, while words farther away contribute less.  \n",
        "- **Vocabulary restriction:** Only the selected top 11,000 words are included to keep computation feasible.  \n",
        "\n",
        "This matrix captures **how often words appear near each other**, which forms the basis for **COALS**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3616a405-0559-4be9-88eb-b194ee792218",
      "metadata": {
        "id": "3616a405-0559-4be9-88eb-b194ee792218"
      },
      "outputs": [],
      "source": [
        "# Build a co-occurrence matrix for the given tokens and vocabulary.\n",
        "def build_co_occurrence_matrix(tokens, vocab, matrix_path, mapping_path, window_size=4):\n",
        "    # Vocabulary length\n",
        "    V = len(vocab)\n",
        "    # Create mapping for the vocabulary\n",
        "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "    matrix = np.zeros((V, V), dtype=np.float32)\n",
        "\n",
        "\n",
        "    for i, token in enumerate(tokens):\n",
        "        # Update the counts corresponding to specific token index\n",
        "        if token not in word2idx:\n",
        "            continue\n",
        "        token_idx = word2idx[token]\n",
        "\n",
        "        # Consider window on both sides\n",
        "        start = max(0, i - window_size)\n",
        "        end = min(len(tokens), i + window_size + 1)\n",
        "\n",
        "        for j in range(start, end):\n",
        "            if i == j:\n",
        "                continue\n",
        "            context_word = tokens[j]\n",
        "            # Update counts if the context_word exists in the vocabulary\n",
        "            if context_word in word2idx:\n",
        "                context_idx = word2idx[context_word]\n",
        "                 # Distance from center word\n",
        "                dist = abs(i - j)\n",
        "                # Decrease weight as distance increases\n",
        "                weight = max(0, window_size - dist + 1)\n",
        "                matrix[token_idx, context_idx] += weight\n",
        "    # Save matrix and mapping\n",
        "    np.save(matrix_path, matrix)\n",
        "    with open(mapping_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(word2idx, f, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Co-occurrence matrix saved to {matrix_path}\")\n",
        "    print(f\"Word2idx mapping saved to {mapping_path}\")\n",
        "    print(f\"Co-occurrence matrix shape: {matrix.shape}\")\n",
        "\n",
        "    return matrix, word2idx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a64b3fe-3345-471f-a90b-8610be042384",
      "metadata": {
        "id": "1a64b3fe-3345-471f-a90b-8610be042384"
      },
      "source": [
        "The co-occurrence matrix generated is **saved** into the memory to save recomputation costs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de2c849d-d9bd-4045-8794-f23ca6f5c270",
      "metadata": {
        "id": "de2c849d-d9bd-4045-8794-f23ca6f5c270",
        "outputId": "13a90e5e-6507-4082-c410-1cf26a023cc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Co-occurrence matrix saved to D:/CMI/NLP/mr_co_occurrence_matrix.npy\n",
            "Word2idx mapping saved to D:/CMI/NLP/mr_word2idx.json\n",
            "Co-occurrence matrix shape: (11000, 11000)\n"
          ]
        }
      ],
      "source": [
        "matrix,word2idx=build_co_occurrence_matrix(tokens,top_vocab,\"D:/CMI/NLP/mr_co_occurrence_matrix.npy\",\"D:/CMI/NLP/mr_word2idx.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c865267-4aed-4383-8760-29723fb5d504",
      "metadata": {
        "id": "7c865267-4aed-4383-8760-29723fb5d504"
      },
      "source": [
        "### Loading and Inspecting the Co-occurrence Matrix\n",
        "\n",
        "After building and saving the co-occurrence matrix and word-to-index mapping, we can **reload them from disk** to avoid recomputation.\n",
        "\n",
        "We perform some **basic sanity checks**:\n",
        "\n",
        "1. **Matrix shape:** Confirms the dimensions match the vocabulary size $(V × V)$.  \n",
        "2. **Non-zero entries:** Shows how many word pairs actually co-occur in the corpus.  \n",
        "3. **Sum of all counts:** Total number of co-occurrences captured in the matrix.  \n",
        "4. **Sample row:** Examines context counts for a sample word to ensure the matrix accurately reflects word co-occurrences with ramped weights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b15f1d-f22e-4215-8724-2ac153831833",
      "metadata": {
        "id": "85b15f1d-f22e-4215-8724-2ac153831833",
        "outputId": "b36d0c31-1b91-4222-8bab-a61128fc0f3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix shape: (11000, 11000)\n",
            "Total non-zero entries: 10362131\n",
            "Sum of all counts: 154743410.0\n",
            "Context counts for 'जमीन':\n",
            "   पुनर्निर्देशन: 35.0\n",
            "   मध्ये: 90.0\n",
            "   जिल्ह्यातील: 94.0\n",
            "   इस: 7.0\n",
            "   तालुक्यातील: 25.0\n",
            "   गावे: 67.0\n",
            "   भारतीय: 29.0\n",
            "   क्रिकेट: 6.0\n",
            "   असते: 79.0\n",
            "   अंतरावर: 3.0\n",
            "   त्यांनी: 76.0\n"
          ]
        }
      ],
      "source": [
        "# Load matrix and mapping\n",
        "matrix = np.load(\"D:/CMI/NLP/mr_co_occurrence_matrix.npy\")\n",
        "with open(\"D:/CMI/NLP/mr_word2idx.json\", 'r', encoding='utf-8') as f:\n",
        "    word2idx = json.load(f)\n",
        "\n",
        "print(\"Matrix shape:\", matrix.shape)\n",
        "\n",
        "# Quick stats\n",
        "print(\"Total non-zero entries:\", np.count_nonzero(matrix))\n",
        "print(\"Sum of all counts:\", matrix.sum())\n",
        "\n",
        "# Check a random row of the matrix\n",
        "sample_word = list(word2idx.keys())[99]  # just the 100th word in vocab\n",
        "idx = word2idx[sample_word]\n",
        "row = matrix[idx]\n",
        "\n",
        "print(f\"Context counts for '{sample_word}':\")\n",
        "nonzero_indices = row.nonzero()[0]\n",
        "for i in nonzero_indices[:11]:  # show first 11 contexts\n",
        "    context_word = [w for w, j in word2idx.items() if j == i][0]\n",
        "    print(f\"   {context_word}: {row[i]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7340c851-d842-4f5a-8fce-6d8fbec4bb85",
      "metadata": {
        "id": "7340c851-d842-4f5a-8fce-6d8fbec4bb85",
        "outputId": "30a02e39-88b8-4b05-9a47-750831b6fcb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample word: 'जमीन'\n",
            "\n",
            "Top co-occurring words:\n",
            "  पडीक: 26444.0\n",
            "  एकूण: 13679.0\n",
            "  पिकांखालची: 10422.0\n",
            "  कायमस्वरूपी: 8559.0\n",
            "  झाडीखालची: 8514.0\n",
            "\n",
            "Least co-occurring words (non-zero):\n",
            "  दळणवळण: 1.0\n",
            "  मिलीमीटर: 1.0\n",
            "  मोकळ्या: 1.0\n",
            "  ठेवावे: 1.0\n",
            "  बाग: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Load matrix and mapping\n",
        "matrix = np.load(\"D:/CMI/NLP/mr_co_occurrence_matrix.npy\")\n",
        "with open(\"D:/CMI/NLP/mr_word2idx.json\", 'r', encoding='utf-8') as f:\n",
        "    word2idx = json.load(f)\n",
        "\n",
        "idx2word = {v: k for k, v in word2idx.items()}  # reverse mapping\n",
        "\n",
        "# Pick a sample word\n",
        "sample_word = list(word2idx.keys())[99]  # 100th word in vocab\n",
        "idx = word2idx[sample_word]\n",
        "row = matrix[idx]\n",
        "\n",
        "# Sort indices by co-occurrence counts\n",
        "sorted_indices = np.argsort(row)  # ascending order\n",
        "\n",
        "# Highest co-occurrences\n",
        "top_indices = [i for i in sorted_indices[::-1] if i != idx][:5]\n",
        "\n",
        "# Lowest non-zero co-occurrences\n",
        "least_indices = [i for i in sorted_indices if row[i] > 0 and i != idx][:5]\n",
        "\n",
        "print(f\"Sample word: '{sample_word}'\\n\")\n",
        "\n",
        "print(\"Top co-occurring words:\")\n",
        "for i in top_indices:\n",
        "    print(f\"  {idx2word[i]}: {row[i]}\")\n",
        "\n",
        "print(\"\\nLeast co-occurring words (non-zero):\")\n",
        "for i in least_indices:\n",
        "    print(f\"  {idx2word[i]}: {row[i]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebb40200-433b-4bcc-af71-23abac313600",
      "metadata": {
        "id": "ebb40200-433b-4bcc-af71-23abac313600"
      },
      "source": [
        "### Co-occurrence Analysis for 'जमीन' (Land)\n",
        "\n",
        "**Top Co-occurring Words:**\n",
        "\n",
        "| Word (Marathi) | Translation (English) | Count |\n",
        "|----------------|-----------------------|-------|\n",
        "| पडीक           | Barren                | 26444 |\n",
        "| एकूण           | Total                 | 13679 |\n",
        "| पिकांखालची     | Under crops           | 10422 |\n",
        "| कायमस्वरूपी    | Permanent             | 8559  |\n",
        "| झाडीखालची     | Under shrubs          | 8514  |\n",
        "\n",
        "**Least Co-occurring Words (non-zero):**\n",
        "\n",
        "| Word (Marathi) | Translation (English) | Count |\n",
        "|----------------|-----------------------|-------|\n",
        "| दळणवळण         | Transportation        | 1     |\n",
        "| मिलीमीटर       | Millimeter            | 1     |\n",
        "| मोकळ्या         | Open                  | 1     |\n",
        "| ठेवावे          | To keep               | 1     |\n",
        "| बाग             | Garden                | 1     |\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "- The **top co-occurring words** are strongly context-related to land, covering themes of productivity (`पडीक`), extent (`एकूण`), cultivation (`पिकांखालची`), and permanence (`कायमस्वरूपी`).  \n",
        "- The **least co-occurring words** are weakly or unrelated, such as transportation (`दळणवळण`) or units of measurement (`मिलीमीटर`), showing that the matrix distinguishes meaningful contexts instead of random overlaps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b8894c8-86f4-441c-ab62-ce294543c6b7",
      "metadata": {
        "id": "5b8894c8-86f4-441c-ab62-ce294543c6b7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca3263ff-33ca-47b6-aff3-f95fd17ed765",
      "metadata": {
        "id": "ca3263ff-33ca-47b6-aff3-f95fd17ed765"
      },
      "source": [
        "### Task 2: Parallelize Correlation Computation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca2cb4c0-06eb-4d89-9d15-8061ac1f11e8",
      "metadata": {
        "id": "ca2cb4c0-06eb-4d89-9d15-8061ac1f11e8"
      },
      "source": [
        "Print and store the number of **CPU cores**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b22c6feb-5048-4c7a-8e5c-477470ff1c3d",
      "metadata": {
        "id": "b22c6feb-5048-4c7a-8e5c-477470ff1c3d",
        "outputId": "76c041d1-40f6-49fa-9e5a-a96a231e3766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of CPU cores available: 12\n"
          ]
        }
      ],
      "source": [
        "num_cores = os.cpu_count()\n",
        "print(f\"Number of CPU cores available: {num_cores}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ae2d172-5449-48aa-889a-96d6c518497d",
      "metadata": {
        "id": "7ae2d172-5449-48aa-889a-96d6c518497d"
      },
      "source": [
        "### Parallelize Correlation Computation\n",
        "  \n",
        "Computing **Pearson correlations** sequentially for each row is **computationally expensive O(V³)**, so we parallelize the computation using **Python’s `joblib.Parallel`**.\n",
        "\n",
        "- Each row of the correlation matrix represents the correlation of one word with all others.\n",
        "- Using multiple CPU cores allows us to **compute multiple rows simultaneously**, significantly reducing total computation time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3c5b74a-a64f-4fa2-927b-8e527515c7bc",
      "metadata": {
        "id": "e3c5b74a-a64f-4fa2-927b-8e527515c7bc"
      },
      "outputs": [],
      "source": [
        "# Compute Pearson coefficient of one row with all the other rows\n",
        "def compute_correlation_row(row_idx, cooc_matrix):\n",
        "    row = cooc_matrix[row_idx, :]\n",
        "    correlations = []\n",
        "\n",
        "    for other_row in cooc_matrix:\n",
        "        # Center the rows\n",
        "        row_centered = row - row.mean()\n",
        "        other_centered = other_row - other_row.mean()\n",
        "\n",
        "        # Pearson correlation\n",
        "        numerator = np.dot(row_centered, other_centered)\n",
        "        denominator = np.linalg.norm(row_centered) * np.linalg.norm(other_centered)\n",
        "        corr = numerator / denominator if denominator != 0 else 0\n",
        "\n",
        "        correlations.append(corr)\n",
        "\n",
        "    return np.array(correlations, dtype=np.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44056c56-9388-4841-8915-443f57678b51",
      "metadata": {
        "id": "44056c56-9388-4841-8915-443f57678b51"
      },
      "source": [
        "### Sequential vs Parallel Computation\n",
        "\n",
        "We computed the first 5 rows of the Pearson correlation matrix to compare **sequential and parallel execution**:\n",
        "\n",
        "- Sequential computation processes each row one by one.  \n",
        "- Parallel computation uses **`joblib.Parallel(n_jobs=12)`** to process multiple rows simultaneously.  \n",
        "\n",
        "**Observation:**  \n",
        "\n",
        "- Sequential computation: **13.3 seconds**  \n",
        "- Parallel computation: **2.88 seconds**  \n",
        "\n",
        "> Parallelization significantly speeds up correlation computation, making it feasible for our full vocabulary (~11,000 words).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f14ae5d-077f-4c74-a308-fad4c60f9c0b",
      "metadata": {
        "id": "6f14ae5d-077f-4c74-a308-fad4c60f9c0b",
        "outputId": "55d9c09e-2d8d-4dd3-bb85-bf34a2be8acd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of CPU cores available: 12\n",
            "Parallel computation done for first 5 rows.\n",
            "Shape of results array: (5, 11000)\n",
            "First 10 correlations for row 0:\n",
            "[1.         0.14331084 0.03758307 0.30042824 0.0303821  0.03245927\n",
            " 0.33180332 0.36542404 0.00521152 0.00626004]\n",
            "Execution time: 2.88 seconds\n"
          ]
        }
      ],
      "source": [
        "# Number of CPU cores\n",
        "num_cores = os.cpu_count()\n",
        "print(f\"Number of CPU cores available: {num_cores}\")\n",
        "\n",
        "# Sample rows\n",
        "rows_to_compute = range(5)  # first 5 rows\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Create a list of delayed tasks\n",
        "tasks = []\n",
        "for i in rows_to_compute:\n",
        "    task = delayed(compute_correlation_row)(i, matrix)\n",
        "    tasks.append(task)\n",
        "\n",
        "# Run tasks in parallel\n",
        "parallel_results = Parallel(n_jobs=num_cores)(tasks)\n",
        "\n",
        "# Stop timer\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "# Convert list of arrays to NumPy array\n",
        "parallel_results_array = np.array(parallel_results, dtype=np.float32)\n",
        "print(\"Parallel computation done for first 5 rows.\")\n",
        "print(\"Shape of results array:\", parallel_results_array.shape)\n",
        "\n",
        "# Inspect first row\n",
        "print(\"First 10 correlations for row 0:\")\n",
        "print(parallel_results_array[0][:10])\n",
        "\n",
        "# Print execution time\n",
        "print(f\"Execution time: {elapsed_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04f01b4e-ecda-494c-b010-ed9894ffe1b0",
      "metadata": {
        "id": "04f01b4e-ecda-494c-b010-ed9894ffe1b0",
        "outputId": "4ee198b7-ad17-49a4-a55d-bb31ee4a2a0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential computation done for first 5 rows.\n",
            "Shape of results array: (5, 11000)\n",
            "First 10 correlations for row 0 (sequential):\n",
            "[1.         0.14331073 0.03758305 0.30042833 0.03038209 0.03245925\n",
            " 0.33180332 0.36542416 0.00521152 0.00626004]\n",
            "Execution time (sequential): 13.30 seconds\n"
          ]
        }
      ],
      "source": [
        "# Sequential computation of the first 5 rows\n",
        "start_time_seq = time.time()\n",
        "\n",
        "seq_results = []\n",
        "for i in rows_to_compute:\n",
        "    row_corr = compute_correlation_row(i, matrix)\n",
        "    seq_results.append(row_corr)\n",
        "\n",
        "seq_results_array = np.array(seq_results, dtype=np.float32)\n",
        "\n",
        "end_time_seq = time.time()\n",
        "elapsed_time_seq = end_time_seq - start_time_seq\n",
        "\n",
        "print(\"Sequential computation done for first 5 rows.\")\n",
        "print(\"Shape of results array:\", seq_results_array.shape)\n",
        "print(\"First 10 correlations for row 0 (sequential):\")\n",
        "print(seq_results_array[0][:10])\n",
        "print(f\"Execution time (sequential): {elapsed_time_seq:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b06d7c1-1be1-47b7-a1b0-241a2e88a7a3",
      "metadata": {
        "id": "1b06d7c1-1be1-47b7-a1b0-241a2e88a7a3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dca35777-d41a-4873-a9ed-de1bea71a908",
      "metadata": {
        "id": "dca35777-d41a-4873-a9ed-de1bea71a908"
      },
      "source": [
        "### Task 3 Compute Pearson Correlation Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81420071-01db-4898-859f-bb232c7c1d1b",
      "metadata": {
        "id": "81420071-01db-4898-859f-bb232c7c1d1b"
      },
      "source": [
        "For this task, we reuse the `compute_correlation_row` function from Task 2, but this time we **compute correlations for all words in the vocabulary (~11,000)** using parallel processing.\n",
        "\n",
        "- **`joblib.Parallel`** utilizes all available CPU cores (12 cores here) to speed up computation.  \n",
        "- The result is the **full Pearson correlation matrix**.\n",
        "\n",
        "**Results:**\n",
        "\n",
        "- Vocabulary size: 11,000  \n",
        "- Correlation matrix: (11,000 × 11,000)  \n",
        "- Time taken: ~57.68 minutes  \n",
        "\n",
        "> Using parallelization makes the computation feasible for the full vocabulary. Sequential computation for this scale would have taken several **hours**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "839e427a-3598-4303-ba5b-2b1d068931cd",
      "metadata": {
        "id": "839e427a-3598-4303-ba5b-2b1d068931cd",
        "outputId": "57442729-bc07-4e32-9287-ce0b1501b298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of CPU cores: 12\n",
            "Correlation matrix shape: (11000, 11000)\n",
            "Elapsed time: 57.68 minutes\n"
          ]
        }
      ],
      "source": [
        "vocab_size = matrix.shape[0]\n",
        "# number of CPU cores\n",
        "num_cores = os.cpu_count()\n",
        "print(f\"Number of CPU cores: {num_cores}\")\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Run tasks in parallel\n",
        "correlation_matrix = Parallel(n_jobs=num_cores)(\n",
        "    delayed(compute_correlation_row)(i, matrix) for i in range(vocab_size)\n",
        ")\n",
        "\n",
        "correlation_matrix = np.array(correlation_matrix, dtype=np.float32)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Correlation matrix shape:\", correlation_matrix.shape)\n",
        "print(f\"Elapsed time: {elapsed_time/60:.2f} minutes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2189589d-b393-42d1-a8ac-fc1aacc2a29c",
      "metadata": {
        "id": "2189589d-b393-42d1-a8ac-fc1aacc2a29c"
      },
      "source": [
        "We **save the correlation matrix** generated and the **word to index mappings**, on the disk, to save on the recomputation costs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b5dd15-885c-4829-9d32-be267de274d1",
      "metadata": {
        "id": "82b5dd15-885c-4829-9d32-be267de274d1",
        "outputId": "af03be8a-6ac7-4696-f1da-6cafbeede8cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved correlation matrix and word2idx mapping.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Save\n",
        "np.save(\"D:/CMI/NLP/mr_correlation_matrix_updated.npy\", correlation_matrix)\n",
        "with open(\"D:/CMI/NLP/mr_word2idx_corr_updated.json\", \"w\") as f:\n",
        "    json.dump(word2idx, f)\n",
        "\n",
        "print(\"Saved correlation matrix and word2idx mapping.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9df23873-8a58-430c-b08c-2d55652f2226",
      "metadata": {
        "id": "9df23873-8a58-430c-b08c-2d55652f2226",
        "outputId": "fc7e63f8-af52-4cd9-9009-a6f93a25cebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation matrix loaded. Shape: (11000, 11000)\n"
          ]
        }
      ],
      "source": [
        "# Load the correlation matrix\n",
        "correlation_matrix = np.load(\"D:/CMI/NLP/mr_correlation_matrix_updated.npy\")\n",
        "print(\"Correlation matrix loaded. Shape:\", correlation_matrix.shape)\n",
        "\n",
        "# Load the word2idx mapping\n",
        "with open(\"D:/CMI/NLP/mr_word2idx_corr_updated.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    word2idx = json.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "664d9b55-7b07-4305-a976-2133431ef16c",
      "metadata": {
        "id": "664d9b55-7b07-4305-a976-2133431ef16c"
      },
      "source": [
        "### Generating Sparse COALS Embeddings\n",
        "\n",
        "We generate **sparse COALS word embeddings** from the full Pearson correlation matrix by:\n",
        "\n",
        "1. Setting all **negative correlations to zero** (COALS ignores negative associations).  \n",
        "2. Applying **square root scaling** to positive correlations to reduce the effect of very strong correlations.  \n",
        "3. **L2 normalizing** each row to produce unit-length word vectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a04f217b-2a8b-4a08-aff5-c971b2927d86",
      "metadata": {
        "id": "a04f217b-2a8b-4a08-aff5-c971b2927d86"
      },
      "outputs": [],
      "source": [
        "# Generate sparse COALS word embeddings from the full Pearson correlation matrix.\n",
        "def generate_coals_embeddings(correlation_matrix):\n",
        "    # Set all negative correlations to zero.\n",
        "    coals_matrix = np.maximum(correlation_matrix, 0)\n",
        "\n",
        "    # Apply square root scaling to positive correlations.\n",
        "    coals_matrix = np.sqrt(coals_matrix)\n",
        "\n",
        "    # L2 normalize rows\n",
        "    row_norms = np.linalg.norm(coals_matrix, axis=1, keepdims=True)\n",
        "    coals_matrix = coals_matrix / np.maximum(row_norms, 1e-8)\n",
        "\n",
        "    return coals_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0a1636e-8944-4721-9daa-e6cf54c1499b",
      "metadata": {
        "id": "d0a1636e-8944-4721-9daa-e6cf54c1499b"
      },
      "outputs": [],
      "source": [
        "coals_matrix=generate_coals_embeddings(correlation_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d60dbb68-ae5a-4d45-b7b2-a66652cf5329",
      "metadata": {
        "id": "d60dbb68-ae5a-4d45-b7b2-a66652cf5329"
      },
      "source": [
        "### Counting Word Frequencies\n",
        "\n",
        "We first compute the **frequency of each word** in the cleaned Marathi corpus.  \n",
        "\n",
        "- The `get_word_counts` function reads the corpus line by line, tokenizes it, and counts the occurrences of each word.  \n",
        "- This helps us identify the **most common words**, which can be useful for selecting **target words** (nouns, verbs, adjectives) for similarity analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "647170a6-ef65-48d3-b168-759f28a5a993",
      "metadata": {
        "id": "647170a6-ef65-48d3-b168-759f28a5a993",
        "outputId": "cb41b7bc-d0bc-4520-a23c-b909f4c3216f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 20 most frequent words:\n",
            "[('पुनर्निर्देशन', 77186), ('मध्ये', 64461), ('जिल्ह्यातील', 53862), ('इस', 50062), ('तालुक्यातील', 49517), ('गावे', 49275), ('भारतीय', 42162), ('क्रिकेट', 41486), ('असते', 40515), ('भोपाळ', 39346), ('अंतरावर', 38640), ('गंगू', 36781), ('त्यांनी', 36101), ('महाराष्ट्र', 34694), ('मधील', 33904), ('राजा', 33533), ('हवामान', 33039), ('जाते', 32728), ('तेली', 32477), ('किमी', 32287)]\n"
          ]
        }
      ],
      "source": [
        "#Helper fucntion to get top_words\n",
        "# Get word_counts\n",
        "def get_word_counts(corpus_path):\n",
        "    word_counts = Counter()\n",
        "    with open(corpus_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            tokens = line.strip().split()\n",
        "            word_counts.update(tokens)\n",
        "    return word_counts\n",
        "\n",
        "\n",
        "corpus_path = \"D:/CMI/NLP/mrwiki_tokens_stopwords_removed.txt\"\n",
        "word_counts = get_word_counts(corpus_path)\n",
        "\n",
        "# Check top 20 words\n",
        "print(\"Top 20 most frequent words:\")\n",
        "print(word_counts.most_common(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "545f95a0-abcc-4c57-9ae2-838845d9388a",
      "metadata": {
        "collapsed": true,
        "id": "545f95a0-abcc-4c57-9ae2-838845d9388a",
        "outputId": "0ecc4233-b9a4-44b3-c64c-95ca798c5a24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('पुनर्निर्देशन', 77186),\n",
              " ('मध्ये', 64461),\n",
              " ('जिल्ह्यातील', 53862),\n",
              " ('इस', 50062),\n",
              " ('तालुक्यातील', 49517),\n",
              " ('गावे', 49275),\n",
              " ('भारतीय', 42162),\n",
              " ('क्रिकेट', 41486),\n",
              " ('असते', 40515),\n",
              " ('भोपाळ', 39346),\n",
              " ('अंतरावर', 38640),\n",
              " ('गंगू', 36781),\n",
              " ('त्यांनी', 36101),\n",
              " ('महाराष्ट्र', 34694),\n",
              " ('मधील', 33904),\n",
              " ('राजा', 33533),\n",
              " ('हवामान', 33039),\n",
              " ('जाते', 32728),\n",
              " ('तेली', 32477),\n",
              " ('किमी', 32287),\n",
              " ('गाव', 31967),\n",
              " ('राज्यातील', 31440),\n",
              " ('भोज', 29890),\n",
              " ('पर्यंत', 29412),\n",
              " ('असतो', 27907),\n",
              " ('यांनी', 25590),\n",
              " ('मराठी', 25417),\n",
              " ('भारतातील', 24110),\n",
              " ('किंवा', 23753),\n",
              " ('च्या', 22624),\n",
              " ('तापमान', 21584),\n",
              " ('पुरस्कार', 21472),\n",
              " ('जन्म', 21257),\n",
              " ('रोजी', 20881),\n",
              " ('पेक्षा', 20476),\n",
              " ('कुठे', 20141),\n",
              " ('शहर', 20108),\n",
              " ('त्यांच्या', 20053),\n",
              " ('चित्रपट', 19959),\n",
              " ('खेळाडू', 19534),\n",
              " ('व्या', 19456),\n",
              " ('पुरुष', 19444),\n",
              " ('उष्ण', 18939),\n",
              " ('नाव', 18813),\n",
              " ('राष्ट्रीय', 18679),\n",
              " ('इतर', 18678),\n",
              " ('गांगेय', 18533),\n",
              " ('महिला', 17472),\n",
              " ('भारताच्या', 17423),\n",
              " ('गावात', 17343)]"
            ]
          },
          "execution_count": 595,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_counts.most_common(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40269a40-ea0f-44ce-99e1-69c846038923",
      "metadata": {
        "id": "40269a40-ea0f-44ce-99e1-69c846038923"
      },
      "source": [
        "### Selecting Target Words\n",
        "\n",
        "For evaluating the quality of COALS embeddings, we select **target words** across three parts of speech:\n",
        "\n",
        "- **Nouns:** चित्रपट (movie), गावे (villages), विधानसभा (assembly), फेब्रुवारी (February), गंगू (Gangu)  \n",
        "- **Verbs:** असते (is/exists), जाते (goes), तयार (prepare), गेले (went), करतात (do)  \n",
        "- **Adjectives:** उपलब्ध (available), राष्ट्रीय (national), उष्ण (hot), आंतरराष्ट्रीय (international), मोठे (large)  \n",
        "\n",
        "We map these words to their **indices in the vocabulary**, which allows us to quickly extract their corresponding word vectors from the COALS embedding matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b76c30c-ae65-49cf-a27e-b6f1e8ec1892",
      "metadata": {
        "id": "3b76c30c-ae65-49cf-a27e-b6f1e8ec1892",
        "outputId": "cefb1786-88aa-40d4-c3b5-3ba3bbffe11b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'nouns': [38, 5, 101, 76, 11], 'verbs': [8, 17, 144, 77, 125], 'adjectives': [97, 44, 42, 55, 98]}\n"
          ]
        }
      ],
      "source": [
        "# Map words to their indices in the vocabulary.\n",
        "idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "# Chosen target words\n",
        "target_words = {\n",
        "    'nouns': ['चित्रपट', 'गावे', 'विधानसभा', 'फेब्रुवारी', 'गंगू'],\n",
        "    'verbs': ['असते', 'जाते', 'तयार', 'गेले', 'करतात'],  # adjust if needed\n",
        "    'adjectives': ['उपलब्ध', 'राष्ट्रीय', 'उष्ण', 'आंतरराष्ट्रीय', 'मोठे']\n",
        "}\n",
        "\n",
        "# Map to indices\n",
        "target_indices = {pos: [word2idx[w] for w in words if w in word2idx]\n",
        "                  for pos, words in target_words.items()}\n",
        "\n",
        "print(target_indices)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebcca6d4-d08e-46da-bffb-8e1d818c72ce",
      "metadata": {
        "id": "ebcca6d4-d08e-46da-bffb-8e1d818c72ce"
      },
      "source": [
        "### Finding Top Similar Words\n",
        "\n",
        "We compute the **top 5 words most similar** to each target word using the **sparse COALS embeddings**:\n",
        "\n",
        "1. For each target word, we extract its **embedding vector** from the COALS matrix.  \n",
        "2. Compute **cosine similarity** with all other words by taking the dot product, then convert it to **cosine distance** using:  \n",
        "   $$\n",
        "   \\text{cosine distance} = 1 - \\text{cosine similarity}\n",
        "   $$\n",
        "3. Exclude the word itself from the ranking.  \n",
        "4. Select the **top 5 closest words** (smallest cosine distance) and record their distance values.  \n",
        "\n",
        "> **Note:** We use cosine distance here. Ranking order remains consistent with using cosine similarity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016514e5-f540-4a8f-a7a8-c8883ff41e95",
      "metadata": {
        "id": "016514e5-f540-4a8f-a7a8-c8883ff41e95"
      },
      "outputs": [],
      "source": [
        "# Compute top-k similar words for each target word using COALS word vectors.\n",
        "def get_similar_words(coals_matrix, idx2word, target_indices, top_k=5):\n",
        "    similar_words = {}\n",
        "\n",
        "    # Normalize vectors to unit length\n",
        "    norms = np.linalg.norm(coals_matrix, axis=1, keepdims=True)\n",
        "    normalized_matrix = coals_matrix / np.maximum(norms, 1e-10)\n",
        "\n",
        "    for pos, indices in target_indices.items():\n",
        "        similar_words[pos] = {}\n",
        "        for idx in indices:\n",
        "            word = idx2word[idx]\n",
        "            vec = normalized_matrix[idx]\n",
        "\n",
        "            # Cosine similarity\n",
        "            sims = normalized_matrix @ vec\n",
        "\n",
        "            # Convert to cosine distance\n",
        "            dists = 1 - sims\n",
        "\n",
        "            # Exclude the word itself\n",
        "            dists[idx] = np.inf  # farthest possible\n",
        "\n",
        "            # Top-k closest words (smallest distance)\n",
        "            topk_idx = np.argsort(dists)[:top_k]\n",
        "            topk_words = [(idx2word[i], dists[i]) for i in topk_idx]\n",
        "\n",
        "            similar_words[pos][word] = topk_words\n",
        "\n",
        "    return similar_words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fba7b6f9-c5af-4ceb-8271-b536f8f362dd",
      "metadata": {
        "id": "fba7b6f9-c5af-4ceb-8271-b536f8f362dd"
      },
      "outputs": [],
      "source": [
        "similar_words = get_similar_words(coals_matrix, idx2word, target_indices, top_k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "661dbe98-cee7-4279-9ac3-2e3f2b43c81e",
      "metadata": {
        "id": "661dbe98-cee7-4279-9ac3-2e3f2b43c81e"
      },
      "source": [
        "### Marathi → English Mapping\n",
        "\n",
        "We maintain a **Marathi → English dictionary** for all target and similar words. This dictionary is **saved and loaded** during execution, allowing us to display **English translations** alongside Marathi words in the similarity tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3de97b8-0d4a-4937-986a-18a2068f06cc",
      "metadata": {
        "id": "b3de97b8-0d4a-4937-986a-18a2068f06cc",
        "outputId": "0b2e6661-0ca5-47ea-c904-0fc7d5944711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dictionary loaded. Sample entries:\n",
            "चित्रपट: movie\n",
            "हिंदी: Hindi\n",
            "बंगाली: Bengali\n",
            "तेलुगू: Telugu\n",
            "गीतकार: songwriter\n"
          ]
        }
      ],
      "source": [
        "# Reload the dictionary\n",
        "with open(\"D:/CMI/NLP/mr_to_en_updated.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    mr_to_en = json.load(f)\n",
        "\n",
        "# Validate Entries\n",
        "print(\"Dictionary loaded. Sample entries:\")\n",
        "for k in list(mr_to_en.keys())[:5]:\n",
        "    print(f\"{k}: {mr_to_en[k]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1ae3726-0337-4e28-92e3-a9d9d9a42a38",
      "metadata": {
        "id": "b1ae3726-0337-4e28-92e3-a9d9d9a42a38"
      },
      "outputs": [],
      "source": [
        "def tabulate_similar_words(similar_words, mr_to_en):\n",
        "    for pos, words in similar_words.items():\n",
        "        # Header\n",
        "        print(\"\\n\" + \"=\"*129)\n",
        "        print(f\"{pos.upper():^129}\")\n",
        "        print(\"=\"*129)\n",
        "\n",
        "        table_dict = {}\n",
        "        for target, sims in words.items():\n",
        "            # Column header: Marathi (English)\n",
        "            col_name = f\"{target} ({mr_to_en.get(target, 'N/A')})\"\n",
        "            # Format: Marathi (English) [score]\n",
        "            table_dict[col_name] = [f\"{w} ({mr_to_en.get(w, 'N/A')}) [{s:.3f}]\" for w, s in sims]\n",
        "\n",
        "        df = pd.DataFrame(table_dict)\n",
        "        display(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42b0e4e6-916e-4a65-a4cd-52f3c3531057",
      "metadata": {
        "id": "42b0e4e6-916e-4a65-a4cd-52f3c3531057",
        "outputId": "20190934-97a4-4fc2-c21f-20554b81212f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================================================================================\n",
            "                                                              NOUNS                                                              \n",
            "=================================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>चित्रपट (movie)</th>\n",
              "      <th>गावे (villages)</th>\n",
              "      <th>विधानसभा (assembly)</th>\n",
              "      <th>फेब्रुवारी (February)</th>\n",
              "      <th>गंगू (Gangu)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>हिंदी (Hindi) [0.010]</td>\n",
              "      <td>वर्धा (Wardha) [0.019]</td>\n",
              "      <td>मतदारसंघ (constituency) [0.026]</td>\n",
              "      <td>नोव्हेंबर (November) [0.007]</td>\n",
              "      <td>तेली (Teli) [0.028]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>बंगाली (Bengali) [0.011]</td>\n",
              "      <td>परभणी (Parbhani) [0.023]</td>\n",
              "      <td>विजापूर (Bijapur) [0.030]</td>\n",
              "      <td>मे (May) [0.023]</td>\n",
              "      <td>म्हणू (saying) [0.138]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>तेलुगू (Telugu) [0.011]</td>\n",
              "      <td>नाशिक (Nashik) [0.023]</td>\n",
              "      <td>बेळगांव (Belgaum) [0.031]</td>\n",
              "      <td>मार्च (March) [0.026]</td>\n",
              "      <td>लागले (took) [0.176]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>गीतकार (songwriter) [0.011]</td>\n",
              "      <td>खेड (village) [0.025]</td>\n",
              "      <td>बिकानेर (Bikaner) [0.032]</td>\n",
              "      <td>एप्रिल (April) [0.028]</td>\n",
              "      <td>गांगेय (Gangean) [0.180]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>मराठी (Marathi) [0.012]</td>\n",
              "      <td>सिंधुदुर्ग (Sindhudurg) [0.029]</td>\n",
              "      <td>गुलबर्गा (Gulbarga) [0.036]</td>\n",
              "      <td>जानेवारी (January) [0.035]</td>\n",
              "      <td>तेलंग (Telang) [0.207]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               चित्रपट (movie)                  गावे (villages)  \\\n",
              "0        हिंदी (Hindi) [0.010]           वर्धा (Wardha) [0.019]   \n",
              "1     बंगाली (Bengali) [0.011]         परभणी (Parbhani) [0.023]   \n",
              "2      तेलुगू (Telugu) [0.011]           नाशिक (Nashik) [0.023]   \n",
              "3  गीतकार (songwriter) [0.011]            खेड (village) [0.025]   \n",
              "4      मराठी (Marathi) [0.012]  सिंधुदुर्ग (Sindhudurg) [0.029]   \n",
              "\n",
              "               विधानसभा (assembly)         फेब्रुवारी (February)  \\\n",
              "0  मतदारसंघ (constituency) [0.026]  नोव्हेंबर (November) [0.007]   \n",
              "1        विजापूर (Bijapur) [0.030]              मे (May) [0.023]   \n",
              "2        बेळगांव (Belgaum) [0.031]         मार्च (March) [0.026]   \n",
              "3        बिकानेर (Bikaner) [0.032]        एप्रिल (April) [0.028]   \n",
              "4      गुलबर्गा (Gulbarga) [0.036]    जानेवारी (January) [0.035]   \n",
              "\n",
              "               गंगू (Gangu)  \n",
              "0       तेली (Teli) [0.028]  \n",
              "1    म्हणू (saying) [0.138]  \n",
              "2      लागले (took) [0.176]  \n",
              "3  गांगेय (Gangean) [0.180]  \n",
              "4    तेलंग (Telang) [0.207]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================================================================================\n",
            "                                                              VERBS                                                              \n",
            "=================================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>असते (is/exists)</th>\n",
              "      <th>जाते (goes)</th>\n",
              "      <th>तयार (ready)</th>\n",
              "      <th>गेले (went)</th>\n",
              "      <th>करतात (do)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>असतो (is/exists) [0.064]</td>\n",
              "      <td>वर (above) [0.031]</td>\n",
              "      <td>विकसित (developed) [0.003]</td>\n",
              "      <td>सामील (included) [0.010]</td>\n",
              "      <td>देतात (give) [0.010]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>पर्यंत (until) [0.069]</td>\n",
              "      <td>गावच्या (of the village) [0.036]</td>\n",
              "      <td>निर्माण (construction) [0.004]</td>\n",
              "      <td>पहिल्यांदा (for the first time) [0.010]</td>\n",
              "      <td>त्यामध्ये (in that) [0.010]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>जाते (goes) [0.072]</td>\n",
              "      <td>बाजारपेठ (market) [0.039]</td>\n",
              "      <td>मदत (help) [0.006]</td>\n",
              "      <td>ब्रिटिशांनी (by British) [0.013]</td>\n",
              "      <td>नाहीत (not) [0.011]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>चांगले (good) [0.072]</td>\n",
              "      <td>ग्रामपंचायत (Gram Panchayat) [0.040]</td>\n",
              "      <td>खरेदी (purchase) [0.006]</td>\n",
              "      <td>अधिकृतपणे (officially) [0.013]</td>\n",
              "      <td>वाढत्या (increasing) [0.011]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>साधारणपणे (usually) [0.076]</td>\n",
              "      <td>गावचे (of the village) [0.042]</td>\n",
              "      <td>स्पष्ट (clear) [0.007]</td>\n",
              "      <td>तिने (she) [0.013]</td>\n",
              "      <td>बऱ्याच (many) [0.011]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              असते (is/exists)                           जाते (goes)  \\\n",
              "0     असतो (is/exists) [0.064]                    वर (above) [0.031]   \n",
              "1       पर्यंत (until) [0.069]      गावच्या (of the village) [0.036]   \n",
              "2          जाते (goes) [0.072]             बाजारपेठ (market) [0.039]   \n",
              "3        चांगले (good) [0.072]  ग्रामपंचायत (Gram Panchayat) [0.040]   \n",
              "4  साधारणपणे (usually) [0.076]        गावचे (of the village) [0.042]   \n",
              "\n",
              "                     तयार (ready)                              गेले (went)  \\\n",
              "0      विकसित (developed) [0.003]                 सामील (included) [0.010]   \n",
              "1  निर्माण (construction) [0.004]  पहिल्यांदा (for the first time) [0.010]   \n",
              "2              मदत (help) [0.006]         ब्रिटिशांनी (by British) [0.013]   \n",
              "3        खरेदी (purchase) [0.006]           अधिकृतपणे (officially) [0.013]   \n",
              "4          स्पष्ट (clear) [0.007]                       तिने (she) [0.013]   \n",
              "\n",
              "                     करतात (do)  \n",
              "0          देतात (give) [0.010]  \n",
              "1   त्यामध्ये (in that) [0.010]  \n",
              "2           नाहीत (not) [0.011]  \n",
              "3  वाढत्या (increasing) [0.011]  \n",
              "4         बऱ्याच (many) [0.011]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================================================================================\n",
            "                                                           ADJECTIVES                                                            \n",
            "=================================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>उपलब्ध (available)</th>\n",
              "      <th>राष्ट्रीय (national)</th>\n",
              "      <th>उष्ण (hot/warm)</th>\n",
              "      <th>आंतरराष्ट्रीय (international)</th>\n",
              "      <th>मोठे (big)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>तार (wire) [0.039]</td>\n",
              "      <td>भारतीय (Indian) [0.017]</td>\n",
              "      <td>वर्षभर (all year) [0.023]</td>\n",
              "      <td>अफगाणिस्तान (Afghanistan) [0.011]</td>\n",
              "      <td>क्रमांकाचे (numbered) [0.052]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>गावात (in village) [0.043]</td>\n",
              "      <td>कबड्डी (Kabaddi) [0.020]</td>\n",
              "      <td>कोरडे (dry) [0.023]</td>\n",
              "      <td>स्कॉटलंड (Scotland) [0.012]</td>\n",
              "      <td>सगळ्यात (most) [0.064]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>सोय (facility) [0.047]</td>\n",
              "      <td>प्रोफाइल (profile) [0.022]</td>\n",
              "      <td>हवामान (climate) [0.025]</td>\n",
              "      <td>महिला (women) [0.012]</td>\n",
              "      <td>लोकसंख्येचे (population) [0.077]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>सोयी (facilities) [0.047]</td>\n",
              "      <td>प्रीमियर (Premier) [0.025]</td>\n",
              "      <td>फारच (very) [0.027]</td>\n",
              "      <td>बल्गेरिया (Bulgaria) [0.012]</td>\n",
              "      <td>सर्वांत (most of all) [0.078]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>व्यवस्था (arrangement) [0.049]</td>\n",
              "      <td>महासंघ (federation) [0.026]</td>\n",
              "      <td>उन्हाळ्यात (in summer) [0.045]</td>\n",
              "      <td>आयर्लंड (Ireland) [0.012]</td>\n",
              "      <td>शहर (city) [0.078]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               उपलब्ध (available)         राष्ट्रीय (national)  \\\n",
              "0              तार (wire) [0.039]      भारतीय (Indian) [0.017]   \n",
              "1      गावात (in village) [0.043]     कबड्डी (Kabaddi) [0.020]   \n",
              "2          सोय (facility) [0.047]   प्रोफाइल (profile) [0.022]   \n",
              "3       सोयी (facilities) [0.047]   प्रीमियर (Premier) [0.025]   \n",
              "4  व्यवस्था (arrangement) [0.049]  महासंघ (federation) [0.026]   \n",
              "\n",
              "                  उष्ण (hot/warm)      आंतरराष्ट्रीय (international)  \\\n",
              "0       वर्षभर (all year) [0.023]  अफगाणिस्तान (Afghanistan) [0.011]   \n",
              "1             कोरडे (dry) [0.023]        स्कॉटलंड (Scotland) [0.012]   \n",
              "2        हवामान (climate) [0.025]              महिला (women) [0.012]   \n",
              "3             फारच (very) [0.027]       बल्गेरिया (Bulgaria) [0.012]   \n",
              "4  उन्हाळ्यात (in summer) [0.045]          आयर्लंड (Ireland) [0.012]   \n",
              "\n",
              "                         मोठे (big)  \n",
              "0     क्रमांकाचे (numbered) [0.052]  \n",
              "1            सगळ्यात (most) [0.064]  \n",
              "2  लोकसंख्येचे (population) [0.077]  \n",
              "3     सर्वांत (most of all) [0.078]  \n",
              "4                शहर (city) [0.078]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calling the display function\n",
        "tabulate_similar_words(similar_words,mr_to_en)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf376cb4-9608-4192-a51c-08e77c93c953",
      "metadata": {
        "id": "cf376cb4-9608-4192-a51c-08e77c93c953"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09a256f5-d5a1-46db-bc5d-387236d116a7",
      "metadata": {
        "id": "09a256f5-d5a1-46db-bc5d-387236d116a7"
      },
      "source": [
        "### Task 4 Apply Singular Value Decomposition (SVD)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24f00bf9-cd8b-413b-aa6f-8440e4ee7f7f",
      "metadata": {
        "id": "24f00bf9-cd8b-413b-aa6f-8440e4ee7f7f"
      },
      "source": [
        "We load the **precomputed Pearson correlation matrix** from disk to proceed with Task 4. This matrix serves as the basis for computing dense word embeddings using SVD.  \n",
        "\n",
        "**Matrix stats** are inspected to ensure validity and sanity before proceeding: minimum, maximum, and mean correlations are checked.  \n",
        "\n",
        "**Note:** Negative correlations are **retained** in this matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94cf28f2-2df0-491d-8f1f-07e22485ea94",
      "metadata": {
        "id": "94cf28f2-2df0-491d-8f1f-07e22485ea94",
        "outputId": "010a13c2-8fbe-4ba9-8ad2-67f24d4b56ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation matrix shape: (11000, 11000)\n",
            "Min correlation: -0.018815007\n",
            "Max correlation: 1.0000001\n",
            "Mean correlation: 0.065918155\n"
          ]
        }
      ],
      "source": [
        "# Load the Pearson correlation matrix\n",
        "correlation_matrix = np.load(\"D:/CMI/NLP/mr_correlation_matrix_updated.npy\")  # adjust path if needed\n",
        "print(\"Correlation matrix shape:\", correlation_matrix.shape)\n",
        "\n",
        "# Check a few stats\n",
        "print(\"Min correlation:\", correlation_matrix.min())\n",
        "print(\"Max correlation:\", correlation_matrix.max())\n",
        "print(\"Mean correlation:\", correlation_matrix.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff6182d9-48fc-42df-891c-2176b88d4ab1",
      "metadata": {
        "id": "ff6182d9-48fc-42df-891c-2176b88d4ab1"
      },
      "source": [
        "We perform **SVD** on the full Pearson correlation matrix (including negative correlations) to obtain dense, lower-dimensional word embeddings.  \n",
        "\n",
        "- **`U, S, Vt = np.linalg.svd(correlation_matrix, full_matrices=False)`** computes the decomposition.\n",
        "- The resulting matrices are **saved** to disk for later use:\n",
        "  - $U$ (left singular vectors)\n",
        "  - $S$ (singular values)\n",
        "  - $V^T$ (right singular vectors)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eae9da96-a52d-42af-a726-e8e5f0e81279",
      "metadata": {
        "id": "eae9da96-a52d-42af-a726-e8e5f0e81279"
      },
      "outputs": [],
      "source": [
        "# Compute the SVD\n",
        "U, S, Vt = np.linalg.svd(correlation_matrix, full_matrices=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a71b7ecd-4e76-4531-8f6e-d7194980b948",
      "metadata": {
        "id": "a71b7ecd-4e76-4531-8f6e-d7194980b948"
      },
      "outputs": [],
      "source": [
        "# Save the SVD\n",
        "np.save('D:/CMI/NLP/corr_SVD_U.npy', U)\n",
        "np.save('D:/CMI/NLP/corr_SVD_S.npy', S)\n",
        "np.save('D:/CMI/NLP/corr_SVD_Vt.npy', Vt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "681bbc39-965a-4628-867a-ada9f6e47865",
      "metadata": {
        "id": "681bbc39-965a-4628-867a-ada9f6e47865"
      },
      "source": [
        "### Minimum Dense Embedding Dimensions via SVD\n",
        "\n",
        "We use the singular values from SVD to determine how many dimensions are needed for dense word embeddings:\n",
        "\n",
        "- For each singular value we compute **explained variance**: $\\frac{S_i^2}{\\sum_j S_j^2} $\n",
        "- We then compute the **cumulative variance** to see how much of the total information is captured as we include more dimensions  \n",
        "- This allows us to pick the **minimum number of dimensions** that retain most of the information\n",
        "\n",
        "- **97% variance retained:** 61 dimensions  \n",
        "- **99% variance retained:** 267 dimensions  \n",
        "\n",
        "> This helps us balance compact embeddings with information retention.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0517978-5a5e-42dd-8cd6-97623cbe22b6",
      "metadata": {
        "id": "e0517978-5a5e-42dd-8cd6-97623cbe22b6"
      },
      "outputs": [],
      "source": [
        "# Explained variance interpreted through singular values from SVD\n",
        "def plot_variance_vs_dimensions(S, variance_thresholds=[97, 99]):\n",
        "\n",
        "    # Explained variance\n",
        "    explained_variance = (S ** 2) / np.sum(S ** 2)\n",
        "    cumulative_variance = np.cumsum(explained_variance) * 100\n",
        "\n",
        "    # Find minimum dimensions for thresholds\n",
        "    min_dims = {}\n",
        "    for th in variance_thresholds:\n",
        "        min_dim = np.argmax(cumulative_variance >= th) + 1\n",
        "        min_dims[th] = min_dim\n",
        "        print(f\"Minimum embedding dimension to reach {th}% variance: {min_dim}\")\n",
        "\n",
        "    # Plot cumulative variance\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(range(1, len(cumulative_variance)+1), cumulative_variance, marker='o', markersize=2, label=\"Cumulative Variance\")\n",
        "    for th, dim in min_dims.items():\n",
        "        plt.axhline(y=th, color='r', linestyle=\"--\", label=f\"{th}% threshold\")\n",
        "        plt.axvline(x=dim, color='g', linestyle=\"--\", label=f\"min dim = {dim} ({th}%)\")\n",
        "    plt.xlabel(\"Embedding Dimension\")\n",
        "    plt.ylabel(\"Cumulative Variance Explained (%)\")\n",
        "    plt.title(\"Variance Retained vs Embedding Dimension\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return min_dims, cumulative_variance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18dd6a39-34d0-4d9a-a82d-9aabbef0ee87",
      "metadata": {
        "id": "18dd6a39-34d0-4d9a-a82d-9aabbef0ee87",
        "outputId": "8ce0838e-205d-4c2e-bf6a-e1c59cd37b48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum embedding dimension to reach 97% variance: 61\n",
            "Minimum embedding dimension to reach 99% variance: 267\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "min_dims, cumulative_variance = plot_variance_vs_dimensions(S)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9493be1f-101a-43fb-8881-5b7ef7a8506d",
      "metadata": {
        "id": "9493be1f-101a-43fb-8881-5b7ef7a8506d"
      },
      "source": [
        "### Computing Dense Word Embeddings from SVD\n",
        "\n",
        "We use the precomputed SVD of the Pearson correlation matrix to generate **dense word embeddings**:\n",
        "\n",
        "- We select the **top `embedding_dim` singular values** and corresponding vectors to form lower-dimensional embeddings:  \n",
        "\n",
        "$$\n",
        "\\text{Dense vectors} = U_{[:, :d]} \\cdot \\sqrt{\\text{diag}(S_{[:d]})}\n",
        "$$\n",
        "\n",
        "- This produces **compact, dense representations** for each word while retaining most of the variance.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9709865-0a05-4705-a7f2-e172baa71a2d",
      "metadata": {
        "id": "c9709865-0a05-4705-a7f2-e172baa71a2d"
      },
      "outputs": [],
      "source": [
        "# Compute dense word embeddings from a correlation matrix using SVD.\n",
        "def compute_dense_embeddings(corr_matrix=None, embedding_dim=300, U=None, S=None, Vt=None):\n",
        "    # Compute SVD only if not provided\n",
        "    if U is None or S is None or Vt is None:\n",
        "        print(\"Precompute SVD before computing embeddings\")\n",
        "    else:\n",
        "        print(\"Using precomputed SVD.\")\n",
        "\n",
        "    # Compute dense embeddings\n",
        "    dense_vectors = np.dot(U[:, :embedding_dim], np.diag(np.sqrt(S[:embedding_dim])))\n",
        "\n",
        "    print(f\"Dense word vectors shape: {dense_vectors.shape}\")\n",
        "    return dense_vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "158f5c00-3911-43fa-9cc5-b317dd0000a6",
      "metadata": {
        "id": "158f5c00-3911-43fa-9cc5-b317dd0000a6",
        "outputId": "4d12a61c-6497-4afd-b06c-0b5f54ebc9e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using precomputed SVD.\n",
            "Dense word vectors shape: (11000, 61)\n"
          ]
        }
      ],
      "source": [
        "dense_vectors_61=compute_dense_embeddings(correlation_matrix,61,U,S,Vt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "600ed9b8-d92c-4f1e-886f-7f3b5f241158",
      "metadata": {
        "id": "600ed9b8-d92c-4f1e-886f-7f3b5f241158",
        "outputId": "c0a8ee2d-abf5-4e57-8c1f-ed592013febb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using precomputed SVD.\n",
            "Dense word vectors shape: (11000, 300)\n"
          ]
        }
      ],
      "source": [
        "dense_vectors_300 = compute_dense_embeddings(correlation_matrix,300,U,S,Vt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63a0b068-b412-4b6a-9d4e-39268835927d",
      "metadata": {
        "id": "63a0b068-b412-4b6a-9d4e-39268835927d",
        "outputId": "7296ca23-14cc-4715-c4b5-0f48a90ce6ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using precomputed SVD.\n",
            "Dense word vectors shape: (11000, 100)\n"
          ]
        }
      ],
      "source": [
        "dense_vectors_100 = compute_dense_embeddings(correlation_matrix,100,U,S,Vt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f4e15d9-0fea-4bf8-a774-c0ca1dddf858",
      "metadata": {
        "id": "5f4e15d9-0fea-4bf8-a774-c0ca1dddf858"
      },
      "outputs": [],
      "source": [
        "# Save dense vectors\n",
        "np.save(\"D:/CMI/NLP/mr_dense_word_vectors_61.npy\", dense_vectors_61)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e654382f-9853-4c64-8d94-23a631ca1102",
      "metadata": {
        "id": "e654382f-9853-4c64-8d94-23a631ca1102"
      },
      "outputs": [],
      "source": [
        "# Save dense vectors\n",
        "np.save(\"D:/CMI/NLP/mr_dense_word_vectors_300.npy\", dense_vectors_300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2cbedb2-ee59-4253-9904-29c1c1877948",
      "metadata": {
        "id": "d2cbedb2-ee59-4253-9904-29c1c1877948"
      },
      "outputs": [],
      "source": [
        "# Save dense vectors\n",
        "np.save(\"D:/CMI/NLP/mr_dense_word_vectors_100.npy\", dense_vectors_100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c407446-eeda-49a0-87fe-30c30bc3d304",
      "metadata": {
        "id": "8c407446-eeda-49a0-87fe-30c30bc3d304"
      },
      "source": [
        "### Finding Similar Words with Dense Embeddings\n",
        "\n",
        "We compute **top-K similar words** using the dense embeddings obtained from SVD:\n",
        "\n",
        "- Cosine distance is used as the similarity measure, defined as $( \\text{cosine distance} = 1 - \\text{cosine similarity} )$.  \n",
        "- The same target words as in Task 3 are considered.  \n",
        "- Top 5 words with the **lowest cosine distance** (most similar) are identified for each target word.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a1d232d-c83e-45b0-bd94-933303950e12",
      "metadata": {
        "id": "6a1d232d-c83e-45b0-bd94-933303950e12"
      },
      "outputs": [],
      "source": [
        "def compute_similar_dense_words(dense_vectors, target_indices, idx2word, top_k=5):\n",
        "    similar_words = {}\n",
        "\n",
        "    for pos, indices in target_indices.items():\n",
        "        similar_words[pos] = {}\n",
        "        for idx in indices:\n",
        "            word = idx2word[idx]\n",
        "            vec = dense_vectors[idx]\n",
        "\n",
        "            # Cosine similarity with all words\n",
        "            sims = dense_vectors @ vec / (norm(dense_vectors, axis=1) * norm(vec))\n",
        "\n",
        "            # Convert similarity to distance\n",
        "            dists = 1 - sims\n",
        "\n",
        "            # Exclude self\n",
        "            dists[idx] = np.inf\n",
        "\n",
        "            # Top K closest words (smallest distance)\n",
        "            top_idx = np.argsort(dists)[:top_k]\n",
        "            similar_words[pos][word] = [(idx2word[i], dists[i]) for i in top_idx]\n",
        "\n",
        "    return similar_words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a29896-5a29-4623-89ea-da68f0235d3f",
      "metadata": {
        "id": "a5a29896-5a29-4623-89ea-da68f0235d3f"
      },
      "outputs": [],
      "source": [
        "dense_similar_words_61 = compute_similar_dense_words(dense_vectors_61, target_indices, idx2word)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb05bdc9-0d8f-4183-a5f2-ade86a580e16",
      "metadata": {
        "id": "cb05bdc9-0d8f-4183-a5f2-ade86a580e16",
        "outputId": "2caf724d-eb7e-4e55-c0d8-6406f966f4bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================================================================================\n",
            "                                                              NOUNS                                                              \n",
            "=================================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>चित्रपट (movie)</th>\n",
              "      <th>गावे (villages)</th>\n",
              "      <th>विधानसभा (assembly)</th>\n",
              "      <th>फेब्रुवारी (February)</th>\n",
              "      <th>गंगू (Gangu)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>अभिनेत्री (actress) [0.078]</td>\n",
              "      <td>रायगड (Raigad) [0.008]</td>\n",
              "      <td>मतदारसंघ (constituency) [0.016]</td>\n",
              "      <td>नोव्हेंबर (November) [0.012]</td>\n",
              "      <td>तेली (Teli) [0.003]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>बंगाली (Bengali) [0.087]</td>\n",
              "      <td>घाडगे (Ghadge) [0.014]</td>\n",
              "      <td>निवडणुकीतील (in elections) [0.025]</td>\n",
              "      <td>उन्हाळा (summer) [0.036]</td>\n",
              "      <td>गांगेय (Gangean) [0.018]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>अभिनेते (actors) [0.094]</td>\n",
              "      <td>सिंधुदुर्ग (Sindhudurg) [0.015]</td>\n",
              "      <td>विधानसभेचा (of assembly) [0.029]</td>\n",
              "      <td>पावसाळा (monsoon) [0.039]</td>\n",
              "      <td>म्हणीमुळे (because of sayings) [0.026]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>दिग्दर्शक (director) [0.106]</td>\n",
              "      <td>रत्‍नागिरी (Ratnagiri) [0.018]</td>\n",
              "      <td>कर्नाटकमधील (in Karnataka) [0.031]</td>\n",
              "      <td>असतेमार्च (It's March) [0.068]</td>\n",
              "      <td>गोष्ट (story) [0.028]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>गीतकार (songwriter) [0.110]</td>\n",
              "      <td>उमरी (Age) [0.018]</td>\n",
              "      <td>परिसीमन (delimitation) [0.032]</td>\n",
              "      <td>हिवाळा (winter) [0.072]</td>\n",
              "      <td>नव्हे (No) [0.030]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                चित्रपट (movie)                  गावे (villages)  \\\n",
              "0   अभिनेत्री (actress) [0.078]           रायगड (Raigad) [0.008]   \n",
              "1      बंगाली (Bengali) [0.087]           घाडगे (Ghadge) [0.014]   \n",
              "2      अभिनेते (actors) [0.094]  सिंधुदुर्ग (Sindhudurg) [0.015]   \n",
              "3  दिग्दर्शक (director) [0.106]   रत्‍नागिरी (Ratnagiri) [0.018]   \n",
              "4   गीतकार (songwriter) [0.110]               उमरी (Age) [0.018]   \n",
              "\n",
              "                  विधानसभा (assembly)           फेब्रुवारी (February)  \\\n",
              "0     मतदारसंघ (constituency) [0.016]    नोव्हेंबर (November) [0.012]   \n",
              "1  निवडणुकीतील (in elections) [0.025]        उन्हाळा (summer) [0.036]   \n",
              "2    विधानसभेचा (of assembly) [0.029]       पावसाळा (monsoon) [0.039]   \n",
              "3  कर्नाटकमधील (in Karnataka) [0.031]  असतेमार्च (It's March) [0.068]   \n",
              "4      परिसीमन (delimitation) [0.032]         हिवाळा (winter) [0.072]   \n",
              "\n",
              "                             गंगू (Gangu)  \n",
              "0                     तेली (Teli) [0.003]  \n",
              "1                गांगेय (Gangean) [0.018]  \n",
              "2  म्हणीमुळे (because of sayings) [0.026]  \n",
              "3                   गोष्ट (story) [0.028]  \n",
              "4                      नव्हे (No) [0.030]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================================================================================\n",
            "                                                              VERBS                                                              \n",
            "=================================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>असते (is/exists)</th>\n",
              "      <th>जाते (goes)</th>\n",
              "      <th>तयार (ready)</th>\n",
              "      <th>गेले (went)</th>\n",
              "      <th>करतात (do)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>गरम (hot) [0.058]</td>\n",
              "      <td>असते (is/exists) [0.139]</td>\n",
              "      <td>विकसित (developed) [0.076]</td>\n",
              "      <td>पहिल्यांदा (for the first time) [0.099]</td>\n",
              "      <td>देतात (give) [0.180]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>सामान्यतः (generally) [0.084]</td>\n",
              "      <td>पावसाळ्यात (during monsoon) [0.170]</td>\n",
              "      <td>गोळा (collect) [0.087]</td>\n",
              "      <td>केल्यावर (after doing) [0.107]</td>\n",
              "      <td>परंपरागत (traditional) [0.186]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>सर्वसाधारण (ordinary) [0.093]</td>\n",
              "      <td>व्हिलेजइन्फोइन (village info) [0.178]</td>\n",
              "      <td>निर्माण (construction) [0.093]</td>\n",
              "      <td>उघडले (opened) [0.112]</td>\n",
              "      <td>अन्न (food) [0.210]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>उष्ण (hot/warm) [0.099]</td>\n",
              "      <td>सेलू (Selu) [0.207]</td>\n",
              "      <td>निश्चित (certain) [0.096]</td>\n",
              "      <td>सामील (included) [0.113]</td>\n",
              "      <td>गावकरी (villagers) [0.222]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>प्रमाणात (in proportion) [0.102]</td>\n",
              "      <td>गाव (village) [0.212]</td>\n",
              "      <td>दुरुस्त (corrected) [0.104]</td>\n",
              "      <td>निपटारा (settlement) [0.116]</td>\n",
              "      <td>आणतात (bring) [0.226]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   असते (is/exists)                            जाते (goes)  \\\n",
              "0                 गरम (hot) [0.058]               असते (is/exists) [0.139]   \n",
              "1     सामान्यतः (generally) [0.084]    पावसाळ्यात (during monsoon) [0.170]   \n",
              "2     सर्वसाधारण (ordinary) [0.093]  व्हिलेजइन्फोइन (village info) [0.178]   \n",
              "3           उष्ण (hot/warm) [0.099]                    सेलू (Selu) [0.207]   \n",
              "4  प्रमाणात (in proportion) [0.102]                  गाव (village) [0.212]   \n",
              "\n",
              "                     तयार (ready)                              गेले (went)  \\\n",
              "0      विकसित (developed) [0.076]  पहिल्यांदा (for the first time) [0.099]   \n",
              "1          गोळा (collect) [0.087]           केल्यावर (after doing) [0.107]   \n",
              "2  निर्माण (construction) [0.093]                   उघडले (opened) [0.112]   \n",
              "3       निश्चित (certain) [0.096]                 सामील (included) [0.113]   \n",
              "4     दुरुस्त (corrected) [0.104]             निपटारा (settlement) [0.116]   \n",
              "\n",
              "                       करतात (do)  \n",
              "0            देतात (give) [0.180]  \n",
              "1  परंपरागत (traditional) [0.186]  \n",
              "2             अन्न (food) [0.210]  \n",
              "3      गावकरी (villagers) [0.222]  \n",
              "4           आणतात (bring) [0.226]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================================================================================\n",
            "                                                           ADJECTIVES                                                            \n",
            "=================================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>उपलब्ध (available)</th>\n",
              "      <th>राष्ट्रीय (national)</th>\n",
              "      <th>उष्ण (hot/warm)</th>\n",
              "      <th>आंतरराष्ट्रीय (international)</th>\n",
              "      <th>मोठे (big)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ऑटोरिक्षा (auto-rickshaw) [0.057]</td>\n",
              "      <td>काँग्रेस (Congress) [0.193]</td>\n",
              "      <td>कोरडे (dry) [0.007]</td>\n",
              "      <td>असोसिएट (associate) [0.060]</td>\n",
              "      <td>वसवले (settled) [0.054]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>दूरध्वनी (telephone) [0.067]</td>\n",
              "      <td>भारतीय (Indian) [0.200]</td>\n",
              "      <td>फारच (very) [0.014]</td>\n",
              "      <td>संघांचे (of teams) [0.067]</td>\n",
              "      <td>राजाची (of king) [0.085]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>स्वयंसहाय्य (self-help) [0.070]</td>\n",
              "      <td>काँग्रेसच्या (of Congress) [0.205]</td>\n",
              "      <td>हवामान (climate) [0.017]</td>\n",
              "      <td>क्रिकेटचे (of cricket) [0.070]</td>\n",
              "      <td>विद्वान (scholar) [0.086]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>रेशन (ration) [0.078]</td>\n",
              "      <td>काँग्रेसचे (Congress’s) [0.216]</td>\n",
              "      <td>वर्षभर (all year) [0.043]</td>\n",
              "      <td>देशांतर्गत (domestically) [0.071]</td>\n",
              "      <td>सगळ्यात (most) [0.109]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>तार (wire) [0.082]</td>\n",
              "      <td>किसान (farmer) [0.221]</td>\n",
              "      <td>वगळता (except) [0.056]</td>\n",
              "      <td>खेळाडूंची (of players) [0.074]</td>\n",
              "      <td>क्रमांकाचे (numbered) [0.120]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  उपलब्ध (available)                राष्ट्रीय (national)  \\\n",
              "0  ऑटोरिक्षा (auto-rickshaw) [0.057]         काँग्रेस (Congress) [0.193]   \n",
              "1       दूरध्वनी (telephone) [0.067]             भारतीय (Indian) [0.200]   \n",
              "2    स्वयंसहाय्य (self-help) [0.070]  काँग्रेसच्या (of Congress) [0.205]   \n",
              "3              रेशन (ration) [0.078]     काँग्रेसचे (Congress’s) [0.216]   \n",
              "4                 तार (wire) [0.082]              किसान (farmer) [0.221]   \n",
              "\n",
              "             उष्ण (hot/warm)      आंतरराष्ट्रीय (international)  \\\n",
              "0        कोरडे (dry) [0.007]        असोसिएट (associate) [0.060]   \n",
              "1        फारच (very) [0.014]         संघांचे (of teams) [0.067]   \n",
              "2   हवामान (climate) [0.017]     क्रिकेटचे (of cricket) [0.070]   \n",
              "3  वर्षभर (all year) [0.043]  देशांतर्गत (domestically) [0.071]   \n",
              "4     वगळता (except) [0.056]     खेळाडूंची (of players) [0.074]   \n",
              "\n",
              "                      मोठे (big)  \n",
              "0        वसवले (settled) [0.054]  \n",
              "1       राजाची (of king) [0.085]  \n",
              "2      विद्वान (scholar) [0.086]  \n",
              "3         सगळ्यात (most) [0.109]  \n",
              "4  क्रमांकाचे (numbered) [0.120]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calling the display function\n",
        "tabulate_similar_words(dense_similar_words_61,mr_to_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca4103ae-1fb8-470a-bb69-c1a3618e9b53",
      "metadata": {
        "id": "ca4103ae-1fb8-470a-bb69-c1a3618e9b53"
      },
      "outputs": [],
      "source": [
        "dense_similar_words_300 = compute_similar_dense_words(dense_vectors_300, target_indices, idx2word)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce4cd48e-1a80-4231-9415-aa26f1a24998",
      "metadata": {
        "id": "ce4cd48e-1a80-4231-9415-aa26f1a24998",
        "outputId": "4c6a1e86-169c-4d48-e931-547be0863fee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================================================================================\n",
            "                                                              NOUNS                                                              \n",
            "=================================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>चित्रपट (movie)</th>\n",
              "      <th>गावे (villages)</th>\n",
              "      <th>विधानसभा (assembly)</th>\n",
              "      <th>फेब्रुवारी (February)</th>\n",
              "      <th>गंगू (Gangu)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>अभिनेत्री (actress) [0.158]</td>\n",
              "      <td>रायगड (Raigad) [0.052]</td>\n",
              "      <td>विधानसभेचा (of assembly) [0.031]</td>\n",
              "      <td>नोव्हेंबर (November) [0.027]</td>\n",
              "      <td>तेली (Teli) [0.006]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>बंगाली (Bengali) [0.163]</td>\n",
              "      <td>सिंधुदुर्ग (Sindhudurg) [0.059]</td>\n",
              "      <td>कर्नाटकमधील (in Karnataka) [0.055]</td>\n",
              "      <td>हिवाळा (winter) [0.113]</td>\n",
              "      <td>गांगेय (Gangean) [0.023]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>चित्रपटसृष्टीतील (in film industry) [0.192]</td>\n",
              "      <td>रत्‍नागिरी (Ratnagiri) [0.060]</td>\n",
              "      <td>निवडणुकीतील (in elections) [0.074]</td>\n",
              "      <td>पावसाळा (monsoon) [0.164]</td>\n",
              "      <td>म्हणीमुळे (because of sayings) [0.037]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>तेलुगु (Telugu) [0.193]</td>\n",
              "      <td>वर्धा (Wardha) [0.062]</td>\n",
              "      <td>दिल्लीमधील (in Delhi) [0.081]</td>\n",
              "      <td>अखेरपर्यंत (until the end) [0.229]</td>\n",
              "      <td>तैलंग (Telang) [0.046]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>भाषेतील (in language) [0.195]</td>\n",
              "      <td>खेड (village) [0.062]</td>\n",
              "      <td>मतदारसंघ (constituency) [0.094]</td>\n",
              "      <td>हंगाम (season) [0.236]</td>\n",
              "      <td>नव्हे (No) [0.046]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               चित्रपट (movie)  \\\n",
              "0                  अभिनेत्री (actress) [0.158]   \n",
              "1                     बंगाली (Bengali) [0.163]   \n",
              "2  चित्रपटसृष्टीतील (in film industry) [0.192]   \n",
              "3                      तेलुगु (Telugu) [0.193]   \n",
              "4                भाषेतील (in language) [0.195]   \n",
              "\n",
              "                   गावे (villages)                 विधानसभा (assembly)  \\\n",
              "0           रायगड (Raigad) [0.052]    विधानसभेचा (of assembly) [0.031]   \n",
              "1  सिंधुदुर्ग (Sindhudurg) [0.059]  कर्नाटकमधील (in Karnataka) [0.055]   \n",
              "2   रत्‍नागिरी (Ratnagiri) [0.060]  निवडणुकीतील (in elections) [0.074]   \n",
              "3           वर्धा (Wardha) [0.062]       दिल्लीमधील (in Delhi) [0.081]   \n",
              "4            खेड (village) [0.062]     मतदारसंघ (constituency) [0.094]   \n",
              "\n",
              "                फेब्रुवारी (February)                            गंगू (Gangu)  \n",
              "0        नोव्हेंबर (November) [0.027]                     तेली (Teli) [0.006]  \n",
              "1             हिवाळा (winter) [0.113]                गांगेय (Gangean) [0.023]  \n",
              "2           पावसाळा (monsoon) [0.164]  म्हणीमुळे (because of sayings) [0.037]  \n",
              "3  अखेरपर्यंत (until the end) [0.229]                  तैलंग (Telang) [0.046]  \n",
              "4              हंगाम (season) [0.236]                      नव्हे (No) [0.046]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================================================================================\n",
            "                                                              VERBS                                                              \n",
            "=================================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>असते (is/exists)</th>\n",
              "      <th>जाते (goes)</th>\n",
              "      <th>तयार (ready)</th>\n",
              "      <th>गेले (went)</th>\n",
              "      <th>करतात (do)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>विषम (odd) [0.187]</td>\n",
              "      <td>खाली (below) [0.395]</td>\n",
              "      <td>विकसित (developed) [0.122]</td>\n",
              "      <td>वसूल (collected) [0.225]</td>\n",
              "      <td>मिळतात (received) [0.345]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>उष्ण (hot/warm) [0.198]</td>\n",
              "      <td>जातेजून (as you go) [0.413]</td>\n",
              "      <td>निर्माण (construction) [0.134]</td>\n",
              "      <td>निजामाने (by Nizam) [0.261]</td>\n",
              "      <td>कुक्कुटपालन (poultry farming) [0.355]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>सामान्यतः (generally) [0.225]</td>\n",
              "      <td>से (as like) [0.444]</td>\n",
              "      <td>गोळा (collect) [0.173]</td>\n",
              "      <td>कर (tax) [0.261]</td>\n",
              "      <td>बकरीपालन (goat farming) [0.362]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>असतेवार्षिक (annual) [0.227]</td>\n",
              "      <td>तापमान (temperature) [0.448]</td>\n",
              "      <td>निश्चित (certain) [0.177]</td>\n",
              "      <td>सामील (included) [0.273]</td>\n",
              "      <td>मोठया (big) [0.393]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>उन्हाळ्यात (in summer) [0.237]</td>\n",
              "      <td>सेल्सियस (Celsius) [0.464]</td>\n",
              "      <td>सादर (presented) [0.203]</td>\n",
              "      <td>पहिल्यांदा (for the first time) [0.277]</td>\n",
              "      <td>वाढत्या (increasing) [0.406]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 असते (is/exists)                   जाते (goes)  \\\n",
              "0              विषम (odd) [0.187]          खाली (below) [0.395]   \n",
              "1         उष्ण (hot/warm) [0.198]   जातेजून (as you go) [0.413]   \n",
              "2   सामान्यतः (generally) [0.225]          से (as like) [0.444]   \n",
              "3    असतेवार्षिक (annual) [0.227]  तापमान (temperature) [0.448]   \n",
              "4  उन्हाळ्यात (in summer) [0.237]    सेल्सियस (Celsius) [0.464]   \n",
              "\n",
              "                     तयार (ready)                              गेले (went)  \\\n",
              "0      विकसित (developed) [0.122]                 वसूल (collected) [0.225]   \n",
              "1  निर्माण (construction) [0.134]              निजामाने (by Nizam) [0.261]   \n",
              "2          गोळा (collect) [0.173]                         कर (tax) [0.261]   \n",
              "3       निश्चित (certain) [0.177]                 सामील (included) [0.273]   \n",
              "4        सादर (presented) [0.203]  पहिल्यांदा (for the first time) [0.277]   \n",
              "\n",
              "                              करतात (do)  \n",
              "0              मिळतात (received) [0.345]  \n",
              "1  कुक्कुटपालन (poultry farming) [0.355]  \n",
              "2        बकरीपालन (goat farming) [0.362]  \n",
              "3                    मोठया (big) [0.393]  \n",
              "4           वाढत्या (increasing) [0.406]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================================================================================\n",
            "                                                           ADJECTIVES                                                            \n",
            "=================================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>उपलब्ध (available)</th>\n",
              "      <th>राष्ट्रीय (national)</th>\n",
              "      <th>उष्ण (hot/warm)</th>\n",
              "      <th>आंतरराष्ट्रीय (international)</th>\n",
              "      <th>मोठे (big)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>दूरध्वनी (telephone) [0.196]</td>\n",
              "      <td>काँग्रेस (Congress) [0.297]</td>\n",
              "      <td>फारच (very) [0.025]</td>\n",
              "      <td>हाँग (Hong) [0.154]</td>\n",
              "      <td>वसवले (settled) [0.056]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>मोबाईल (mobile) [0.211]</td>\n",
              "      <td>संघ (team) [0.304]</td>\n",
              "      <td>कोरडे (dry) [0.027]</td>\n",
              "      <td>महिला (women) [0.158]</td>\n",
              "      <td>विद्वान (scholar) [0.105]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>तार (wire) [0.226]</td>\n",
              "      <td>काँग्रेसच्या (of Congress) [0.313]</td>\n",
              "      <td>उन्हाळ्यात (in summer) [0.070]</td>\n",
              "      <td>संघाविरुद्ध (against the team) [0.178]</td>\n",
              "      <td>राजाची (of king) [0.112]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ऑटोरिक्षा (auto-rickshaw) [0.248]</td>\n",
              "      <td>भारतीय (Indian) [0.317]</td>\n",
              "      <td>हिवाळ्यात (in winter) [0.089]</td>\n",
              "      <td>कसोटी (test) [0.192]</td>\n",
              "      <td>आजतागायत (until today) [0.167]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>गटारव्यवस्था (drainage system) [0.253]</td>\n",
              "      <td>काँग्रेसचे (Congress’s) [0.341]</td>\n",
              "      <td>हवामान (climate) [0.090]</td>\n",
              "      <td>विश्वचषकात (in World Cup) [0.197]</td>\n",
              "      <td>क्रमांकाचे (numbered) [0.226]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       उपलब्ध (available)                राष्ट्रीय (national)  \\\n",
              "0            दूरध्वनी (telephone) [0.196]         काँग्रेस (Congress) [0.297]   \n",
              "1                 मोबाईल (mobile) [0.211]                  संघ (team) [0.304]   \n",
              "2                      तार (wire) [0.226]  काँग्रेसच्या (of Congress) [0.313]   \n",
              "3       ऑटोरिक्षा (auto-rickshaw) [0.248]             भारतीय (Indian) [0.317]   \n",
              "4  गटारव्यवस्था (drainage system) [0.253]     काँग्रेसचे (Congress’s) [0.341]   \n",
              "\n",
              "                  उष्ण (hot/warm)           आंतरराष्ट्रीय (international)  \\\n",
              "0             फारच (very) [0.025]                     हाँग (Hong) [0.154]   \n",
              "1             कोरडे (dry) [0.027]                   महिला (women) [0.158]   \n",
              "2  उन्हाळ्यात (in summer) [0.070]  संघाविरुद्ध (against the team) [0.178]   \n",
              "3   हिवाळ्यात (in winter) [0.089]                    कसोटी (test) [0.192]   \n",
              "4        हवामान (climate) [0.090]       विश्वचषकात (in World Cup) [0.197]   \n",
              "\n",
              "                       मोठे (big)  \n",
              "0         वसवले (settled) [0.056]  \n",
              "1       विद्वान (scholar) [0.105]  \n",
              "2        राजाची (of king) [0.112]  \n",
              "3  आजतागायत (until today) [0.167]  \n",
              "4   क्रमांकाचे (numbered) [0.226]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calling the display function\n",
        "tabulate_similar_words(dense_similar_words_300,mr_to_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1386ec0-034b-48bc-a232-d4b271890cf6",
      "metadata": {
        "id": "f1386ec0-034b-48bc-a232-d4b271890cf6"
      },
      "outputs": [],
      "source": [
        "dense_similar_words_100 = compute_similar_dense_words(dense_vectors_100, target_indices, idx2word)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e088426-4555-4efb-84cb-9b4576fa60da",
      "metadata": {
        "id": "7e088426-4555-4efb-84cb-9b4576fa60da",
        "outputId": "df816b77-970e-462e-9626-12415abf54b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================================================================================\n",
            "                                                              NOUNS                                                              \n",
            "=================================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>चित्रपट (movie)</th>\n",
              "      <th>गावे (villages)</th>\n",
              "      <th>विधानसभा (assembly)</th>\n",
              "      <th>फेब्रुवारी (February)</th>\n",
              "      <th>गंगू (Gangu)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>अभिनेत्री (actress) [0.102]</td>\n",
              "      <td>रायगड (Raigad) [0.013]</td>\n",
              "      <td>मतदारसंघ (constituency) [0.023]</td>\n",
              "      <td>नोव्हेंबर (November) [0.020]</td>\n",
              "      <td>तेली (Teli) [0.002]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>बंगाली (Bengali) [0.110]</td>\n",
              "      <td>सिंधुदुर्ग (Sindhudurg) [0.026]</td>\n",
              "      <td>निवडणुकीतील (in elections) [0.025]</td>\n",
              "      <td>पावसाळा (monsoon) [0.085]</td>\n",
              "      <td>गांगेय (Gangean) [0.007]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>अभिनेते (actors) [0.123]</td>\n",
              "      <td>रत्‍नागिरी (Ratnagiri) [0.027]</td>\n",
              "      <td>विधानसभेचा (of assembly) [0.026]</td>\n",
              "      <td>उन्हाळा (summer) [0.102]</td>\n",
              "      <td>म्हणीमुळे (because of sayings) [0.015]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>गीतकार (songwriter) [0.131]</td>\n",
              "      <td>खेड (village) [0.028]</td>\n",
              "      <td>परिसीमन (delimitation) [0.036]</td>\n",
              "      <td>हिवाळा (winter) [0.103]</td>\n",
              "      <td>तैलंग (Telang) [0.020]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>हिंदी (Hindi) [0.150]</td>\n",
              "      <td>घाडगे (Ghadge) [0.030]</td>\n",
              "      <td>कर्नाटकमधील (in Karnataka) [0.037]</td>\n",
              "      <td>असतेमार्च (It's March) [0.125]</td>\n",
              "      <td>गोष्ट (story) [0.020]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               चित्रपट (movie)                  गावे (villages)  \\\n",
              "0  अभिनेत्री (actress) [0.102]           रायगड (Raigad) [0.013]   \n",
              "1     बंगाली (Bengali) [0.110]  सिंधुदुर्ग (Sindhudurg) [0.026]   \n",
              "2     अभिनेते (actors) [0.123]   रत्‍नागिरी (Ratnagiri) [0.027]   \n",
              "3  गीतकार (songwriter) [0.131]            खेड (village) [0.028]   \n",
              "4        हिंदी (Hindi) [0.150]           घाडगे (Ghadge) [0.030]   \n",
              "\n",
              "                  विधानसभा (assembly)           फेब्रुवारी (February)  \\\n",
              "0     मतदारसंघ (constituency) [0.023]    नोव्हेंबर (November) [0.020]   \n",
              "1  निवडणुकीतील (in elections) [0.025]       पावसाळा (monsoon) [0.085]   \n",
              "2    विधानसभेचा (of assembly) [0.026]        उन्हाळा (summer) [0.102]   \n",
              "3      परिसीमन (delimitation) [0.036]         हिवाळा (winter) [0.103]   \n",
              "4  कर्नाटकमधील (in Karnataka) [0.037]  असतेमार्च (It's March) [0.125]   \n",
              "\n",
              "                             गंगू (Gangu)  \n",
              "0                     तेली (Teli) [0.002]  \n",
              "1                गांगेय (Gangean) [0.007]  \n",
              "2  म्हणीमुळे (because of sayings) [0.015]  \n",
              "3                  तैलंग (Telang) [0.020]  \n",
              "4                   गोष्ट (story) [0.020]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================================================================================\n",
            "                                                              VERBS                                                              \n",
            "=================================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>असते (is/exists)</th>\n",
              "      <th>जाते (goes)</th>\n",
              "      <th>तयार (ready)</th>\n",
              "      <th>गेले (went)</th>\n",
              "      <th>करतात (do)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>गरम (hot) [0.091]</td>\n",
              "      <td>चढते (goes up) [0.223]</td>\n",
              "      <td>विकसित (developed) [0.094]</td>\n",
              "      <td>केल्यावर (after doing) [0.117]</td>\n",
              "      <td>देतात (give) [0.220]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>विषम (odd) [0.095]</td>\n",
              "      <td>असते (is/exists) [0.234]</td>\n",
              "      <td>निर्माण (construction) [0.106]</td>\n",
              "      <td>वसूल (collected) [0.120]</td>\n",
              "      <td>परंपरागत (traditional) [0.257]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>सामान्यतः (generally) [0.103]</td>\n",
              "      <td>पर्यंत (until) [0.242]</td>\n",
              "      <td>निश्चित (certain) [0.124]</td>\n",
              "      <td>इसवी (AD) [0.135]</td>\n",
              "      <td>मिळतात (received) [0.262]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>उष्ण (hot/warm) [0.131]</td>\n",
              "      <td>वर (above) [0.266]</td>\n",
              "      <td>गोळा (collect) [0.125]</td>\n",
              "      <td>पहिल्यांदा (for the first time) [0.141]</td>\n",
              "      <td>शेतकरी (farmer) [0.277]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>असतेदिवसा (N/A) [0.134]</td>\n",
              "      <td>मानवत (humanity) [0.294]</td>\n",
              "      <td>दुरुस्त (corrected) [0.136]</td>\n",
              "      <td>निजामाने (by Nizam) [0.151]</td>\n",
              "      <td>गावकरी (villagers) [0.281]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                असते (is/exists)               जाते (goes)  \\\n",
              "0              गरम (hot) [0.091]    चढते (goes up) [0.223]   \n",
              "1             विषम (odd) [0.095]  असते (is/exists) [0.234]   \n",
              "2  सामान्यतः (generally) [0.103]    पर्यंत (until) [0.242]   \n",
              "3        उष्ण (hot/warm) [0.131]        वर (above) [0.266]   \n",
              "4        असतेदिवसा (N/A) [0.134]  मानवत (humanity) [0.294]   \n",
              "\n",
              "                     तयार (ready)                              गेले (went)  \\\n",
              "0      विकसित (developed) [0.094]           केल्यावर (after doing) [0.117]   \n",
              "1  निर्माण (construction) [0.106]                 वसूल (collected) [0.120]   \n",
              "2       निश्चित (certain) [0.124]                        इसवी (AD) [0.135]   \n",
              "3          गोळा (collect) [0.125]  पहिल्यांदा (for the first time) [0.141]   \n",
              "4     दुरुस्त (corrected) [0.136]              निजामाने (by Nizam) [0.151]   \n",
              "\n",
              "                       करतात (do)  \n",
              "0            देतात (give) [0.220]  \n",
              "1  परंपरागत (traditional) [0.257]  \n",
              "2       मिळतात (received) [0.262]  \n",
              "3         शेतकरी (farmer) [0.277]  \n",
              "4      गावकरी (villagers) [0.281]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================================================================================\n",
            "                                                           ADJECTIVES                                                            \n",
            "=================================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>उपलब्ध (available)</th>\n",
              "      <th>राष्ट्रीय (national)</th>\n",
              "      <th>उष्ण (hot/warm)</th>\n",
              "      <th>आंतरराष्ट्रीय (international)</th>\n",
              "      <th>मोठे (big)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ऑटोरिक्षा (auto-rickshaw) [0.088]</td>\n",
              "      <td>काँग्रेस (Congress) [0.217]</td>\n",
              "      <td>कोरडे (dry) [0.008]</td>\n",
              "      <td>महिला (women) [0.083]</td>\n",
              "      <td>वसवले (settled) [0.040]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>दूरध्वनी (telephone) [0.090]</td>\n",
              "      <td>काँग्रेसच्या (of Congress) [0.224]</td>\n",
              "      <td>फारच (very) [0.015]</td>\n",
              "      <td>हाँग (Hong) [0.085]</td>\n",
              "      <td>राजाची (of king) [0.082]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>तार (wire) [0.105]</td>\n",
              "      <td>भारतीय (Indian) [0.230]</td>\n",
              "      <td>हवामान (climate) [0.027]</td>\n",
              "      <td>असोसिएट (associate) [0.088]</td>\n",
              "      <td>विद्वान (scholar) [0.101]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>पिन (pin) [0.108]</td>\n",
              "      <td>काँग्रेसचे (Congress’s) [0.246]</td>\n",
              "      <td>वर्षभर (all year) [0.063]</td>\n",
              "      <td>देशांतर्गत (domestically) [0.088]</td>\n",
              "      <td>सगळ्यात (most) [0.112]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>स्वयंसहाय्य (self-help) [0.116]</td>\n",
              "      <td>किसान (farmer) [0.252]</td>\n",
              "      <td>वगळता (except) [0.064]</td>\n",
              "      <td>एकदिवसीय (ODI) [0.096]</td>\n",
              "      <td>क्रमांकाचे (numbered) [0.142]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  उपलब्ध (available)                राष्ट्रीय (national)  \\\n",
              "0  ऑटोरिक्षा (auto-rickshaw) [0.088]         काँग्रेस (Congress) [0.217]   \n",
              "1       दूरध्वनी (telephone) [0.090]  काँग्रेसच्या (of Congress) [0.224]   \n",
              "2                 तार (wire) [0.105]             भारतीय (Indian) [0.230]   \n",
              "3                  पिन (pin) [0.108]     काँग्रेसचे (Congress’s) [0.246]   \n",
              "4    स्वयंसहाय्य (self-help) [0.116]              किसान (farmer) [0.252]   \n",
              "\n",
              "             उष्ण (hot/warm)      आंतरराष्ट्रीय (international)  \\\n",
              "0        कोरडे (dry) [0.008]              महिला (women) [0.083]   \n",
              "1        फारच (very) [0.015]                हाँग (Hong) [0.085]   \n",
              "2   हवामान (climate) [0.027]        असोसिएट (associate) [0.088]   \n",
              "3  वर्षभर (all year) [0.063]  देशांतर्गत (domestically) [0.088]   \n",
              "4     वगळता (except) [0.064]             एकदिवसीय (ODI) [0.096]   \n",
              "\n",
              "                      मोठे (big)  \n",
              "0        वसवले (settled) [0.040]  \n",
              "1       राजाची (of king) [0.082]  \n",
              "2      विद्वान (scholar) [0.101]  \n",
              "3         सगळ्यात (most) [0.112]  \n",
              "4  क्रमांकाचे (numbered) [0.142]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calling the display function\n",
        "tabulate_similar_words(dense_similar_words_100,mr_to_en)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ee71dae-0cf9-4e84-942b-a64056d9f476",
      "metadata": {
        "id": "3ee71dae-0cf9-4e84-942b-a64056d9f476"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8186058-ade0-47b5-9596-074b021ad574",
      "metadata": {
        "id": "a8186058-ade0-47b5-9596-074b021ad574"
      },
      "source": [
        "### Task 5 Analysis and Report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6168a6b-ff0c-47ce-897c-2c45aa484219",
      "metadata": {
        "id": "d6168a6b-ff0c-47ce-897c-2c45aa484219"
      },
      "source": [
        "### Computing Most Dissimilar Words\n",
        "\n",
        "In this step, we compute the **bottom-K most dissimilar words** for each target word using cosine similarity of word vectors.  \n",
        "The goal is to identify words that are least similar to a given target word in the embedding space, which can help analyze the semantic structure of the vocabulary and validate the quality of embeddings.\n",
        "\n",
        "**Key points:**\n",
        "- We normalize all word vectors to compute `cosine similarity` efficiently.\n",
        "- For each target word, we calculate cosine similarity with all other words and select the **least similar ones**.\n",
        "- **Garbage or rare tokens** (e.g., abcता) are filtered out using a regex.  \n",
        "  Even after preprocessing, such tokens can escape and appear in the vocabulary.  \n",
        "  Including them could **skew the results** because:\n",
        "  - They often have extremely low or high similarity by chance.  \n",
        "  - They do not represent meaningful words in the language.  \n",
        "- Ensuring only valid language tokens (e.g., Marathi/Devanagari words) keeps the results **clean and interpretable**.\n",
        "\n",
        "Note: Here we use cosine similarity as a measure which means lower the cosine similarity more dissimilar are the words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf5872d4-5fab-42b4-a34f-b678a8c94cc8",
      "metadata": {
        "id": "cf5872d4-5fab-42b4-a34f-b678a8c94cc8"
      },
      "outputs": [],
      "source": [
        "# For each target word, return bottom_k most dissimilar words along with their cosine similarity.\n",
        "def compute_most_dissimilar_words(matrix, target_indices, idx2word, bottom_k=5):\n",
        "    # Normalize vectors\n",
        "    matrix_norm = matrix / norm(matrix, axis=1, keepdims=True)\n",
        "\n",
        "    dissimilar_words = {}\n",
        "\n",
        "    # regex to match valid words for Devanagari / Marathi\n",
        "    valid_word_pattern = re.compile(r'^[\\u0900-\\u097F]+$')\n",
        "\n",
        "    for pos, indices in target_indices.items():\n",
        "        dissimilar_words[pos] = {}\n",
        "        for idx in indices:\n",
        "            word = idx2word[idx]\n",
        "            vec = matrix_norm[idx]\n",
        "\n",
        "            # Cosine similarity with all words\n",
        "            sims = matrix_norm @ vec\n",
        "\n",
        "            # Exclude self\n",
        "            sims[idx] = 1.0\n",
        "\n",
        "            # Filter out invalid / mixed words\n",
        "            valid_indices = [i for i in range(len(idx2word)) if valid_word_pattern.match(idx2word[i])]\n",
        "            valid_sims = sims[valid_indices]\n",
        "\n",
        "            # Get bottom K indices (most negative / least similar)\n",
        "            bottom_order = valid_sims.argsort()[:bottom_k]\n",
        "            bottom_idx = [valid_indices[i] for i in bottom_order]\n",
        "\n",
        "            # Map to words and similarity\n",
        "            dissimilar_words[pos][word] = [(idx2word[i], sims[i]) for i in bottom_idx]\n",
        "\n",
        "    return dissimilar_words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adbd1d9c-dcd5-4746-8b48-0dd675579c6f",
      "metadata": {
        "id": "adbd1d9c-dcd5-4746-8b48-0dd675579c6f"
      },
      "outputs": [],
      "source": [
        "# Single word\n",
        "single_word_target = {'nouns': [38]}\n",
        "\n",
        "# Case A\n",
        "min_sim_caseA = compute_most_dissimilar_words(coals_matrix, single_word_target, idx2word)\n",
        "\n",
        "# Case B\n",
        "min_sim_caseB = compute_most_dissimilar_words(dense_vectors_300, single_word_target, idx2word)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dce524c6-f998-48f9-b045-5644beafc54a",
      "metadata": {
        "id": "dce524c6-f998-48f9-b045-5644beafc54a"
      },
      "source": [
        "### Interpretation of Retaining Negative Correlations in Word Embeddings\n",
        "\n",
        "When we compare COALS (sparse) embeddings with the dense embeddings from SVD, we notice a clear difference in how they show dissimilarity for the word **\"चित्रपट\" (movie)**:\n",
        "\n",
        "**COALS (Sparse Embeddings):**  \n",
        "- The words that are most \"different\" from चित्रपट have small positive similarities (e.g., `सुद [0.050]`, `नेतापद [0.051]`).  \n",
        "- These words are valid Marathi words, but their dissimilarity isn’t very pronounced.\n",
        "\n",
        "**Dense Embeddings (SVD, with Negative Correlations):**  \n",
        "- The most dissimilar words now have noticeably negative similarity scores (e.g., `पापिनिएनस [-0.151]`), showing clear semantic opposition.  \n",
        "- Words like `फेब्रुवारीपर्यंत (until February)` or `शस्त्र (weapon)` are correctly identified as very different from \"movie\".  \n",
        "- Keeping negative correlations helps the embeddings capture **contrast** — something the sparse embeddings miss.\n",
        "\n",
        "**What we can learn from this:**  \n",
        "1. **Richer meaning:** Negative correlations let the model know not just what is similar, but also what is strongly different.  \n",
        "2. **Better separation:** Unrelated words are pushed apart in the vector space.  \n",
        "\n",
        "In short, **retaining negative correlations improves the expressiveness of dense embeddings**, providing clearer distinctions between related and unrelated words, which is especially evident in dissimilarity analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aaed10f-275c-4b42-8f0c-9d42954787de",
      "metadata": {
        "id": "3aaed10f-275c-4b42-8f0c-9d42954787de",
        "outputId": "f9eb97d2-6940-4e65-93f3-9647cd93a3f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================================================================================\n",
            "                                                              NOUNS                                                              \n",
            "=================================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>चित्रपट (movie)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>पापिनिएनस (Unknown) [0.010]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>सुद (Sud (proper name)) [0.050]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>नेतापद (leadership post / position) [0.051]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>नेतानाव (leader name / Chief’s name) [0.051]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>नव्हे (No) [0.057]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                चित्रपट (movie)\n",
              "0                   पापिनिएनस (Unknown) [0.010]\n",
              "1               सुद (Sud (proper name)) [0.050]\n",
              "2   नेतापद (leadership post / position) [0.051]\n",
              "3  नेतानाव (leader name / Chief’s name) [0.051]\n",
              "4                            नव्हे (No) [0.057]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calling the display function\n",
        "tabulate_similar_words(min_sim_caseA,mr_to_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b28d104d-47b5-4f7c-89d2-79168e5a616c",
      "metadata": {
        "id": "b28d104d-47b5-4f7c-89d2-79168e5a616c",
        "outputId": "187ba889-8878-4f21-eee5-c9f6fc2a6067"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=================================================================================================================================\n",
            "                                                              NOUNS                                                              \n",
            "=================================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>चित्रपट (movie)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>पापिनिएनस (Unknown) [-0.151]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>फेब्रुवारीपर्यंत (until February) [-0.020]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>शस्त्र (weapon / Arms) [-0.019]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>शास्त्र (science / subject) [-0.018]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>दोन्हीचा (Of both) [-0.016]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              चित्रपट (movie)\n",
              "0                पापिनिएनस (Unknown) [-0.151]\n",
              "1  फेब्रुवारीपर्यंत (until February) [-0.020]\n",
              "2             शस्त्र (weapon / Arms) [-0.019]\n",
              "3        शास्त्र (science / subject) [-0.018]\n",
              "4                 दोन्हीचा (Of both) [-0.016]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calling the display function\n",
        "tabulate_similar_words(min_sim_caseB,mr_to_en)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9a105be-048b-434d-ade6-7bd42c54234b",
      "metadata": {
        "id": "d9a105be-048b-434d-ade6-7bd42c54234b"
      },
      "source": [
        "### Summary of Implementation and Challenges"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4418213b-62e6-410b-a3c6-e26d09418793",
      "metadata": {
        "id": "4418213b-62e6-410b-a3c6-e26d09418793"
      },
      "source": [
        "### Task 1: Load and Prepare Co-occurrence Matrix\n",
        "\n",
        "**Implementation:**  \n",
        "- Constructed a co-occurrence matrix from the Marathi corpus using a ramped sliding window of size 4.  \n",
        "- Applied distance-based weighting so that words closer to the target word contribute more strongly to the counts.  \n",
        "- Limited the vocabulary to 11,000 words (from a possible 20,000) to balance memory usage and computational efficiency.  \n",
        "- Saved both the matrix and the word-to-index mapping for subsequent tasks.  \n",
        "\n",
        "**Challenges:**  \n",
        "- Preprocessing required careful balancing: we aimed to clean the corpus thoroughly while preserving meaningful tokens. Some rare/mixed words naturally remained, but these were minimal and did not impact overall quality.  \n",
        "- Working with a large vocabulary was memory-intensive; increasing beyond 11,000 words significantly slowed later computations.  \n",
        "\n",
        "**Findings:**  \n",
        "- Successfully generated a co-occurrence matrix capturing meaningful relationships between tokens.  \n",
        "- Sample row checks confirmed that context counts aligned well with expected word co-occurrences, validating the approach.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f846b256-9335-4117-9ab7-44d4d955afe6",
      "metadata": {
        "id": "f846b256-9335-4117-9ab7-44d4d955afe6"
      },
      "source": [
        "### Task 2: Parallelize Correlation Computation\n",
        "\n",
        "**Implementation:**  \n",
        "- Computed the Pearson correlation coefficient for each row of the co-occurrence matrix against all other rows.  \n",
        "- Parallelized the row-wise computation using `joblib.Parallel` with 12 cores, significantly reducing runtime compared to sequential execution.  \n",
        "\n",
        "**Challenges:**  \n",
        "- Ensuring thread-safe access and efficient memory usage while handling a large matrix.  \n",
        "- Balancing the number of parallel jobs with system resources to avoid memory overload.  \n",
        "\n",
        "**Findings:**  \n",
        "- On a small test (first 5 rows), sequential computation took **13.3 seconds**, while parallel computation completed in **2.88 seconds**.  \n",
        "- Even on this small scale, parallelization shows clear advantages. When scaled to the full vocabulary (~11,000 words), this approach yields substantial time savings and makes the computation feasible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0dff2f7-3fe5-477b-bd27-97166b051fb4",
      "metadata": {
        "id": "a0dff2f7-3fe5-477b-bd27-97166b051fb4"
      },
      "source": [
        "### Task 3: Full Pearson Correlation Matrix & COALS Embeddings\n",
        "\n",
        "**Phase 1: Compute Full Pearson Correlation Matrix**  \n",
        "- Computed correlations for all vocabulary words (~11,000) using `compute_correlation_row`.  \n",
        "- Parallelized computation with `joblib.Parallel` using 12 CPU cores to significantly reduce runtime.  \n",
        "- Resulting correlation matrix shape: (11,000 × 11,000).  \n",
        "- Time taken: ~57–60 minutes with parallelization (sequential execution would have taken several hours).  \n",
        "- Saved outputs for later use.\n",
        "\n",
        "\n",
        "\n",
        "**Phase 2: Generate COALS Word Embeddings**\n",
        "\n",
        "**Objective:**  \n",
        "Transform the full Pearson correlation matrix into sparse COALS embeddings that emphasize meaningful co-occurrences while ignoring negative correlations.\n",
        "\n",
        "**Steps:**  \n",
        "1. **Zero-out negative correlations:**  \n",
        "   - Only positive correlations indicate meaningful co-occurrence patterns.  \n",
        "   - Negative correlations are set to 0 to avoid noise from unrelated word pairs.  \n",
        "\n",
        "2. **Square root scaling of positive correlations:**  \n",
        "   - Reduces the impact of extremely high co-occurrence counts.  \n",
        "   - Moderates the effect of very frequent word pairs.  \n",
        "\n",
        "3. **L2 Normalization of rows:**  \n",
        "   - Ensures all word vectors have consistent magnitude.  \n",
        "   - Facilitates cosine similarity computations for evaluating similarity and dissimilarity.\n",
        "\n",
        "**Selecting Target Words for Evaluation:**  \n",
        "- **Nouns:** चित्रपट (movie), गावे (villages), विधानसभा (assembly), फेब्रुवारी (February), गंगू (Gangu)  \n",
        "- **Verbs:** असते (is/exists), जाते (goes), तयार (prepare), गेले (went), करतात (do)  \n",
        "- **Adjectives:** उपलब्ध (available), राष्ट्रीय (national), उष्ण (hot), आंतरराष्ट्रीय (international), मोठे (large)  \n",
        "\n",
        "**Observations:**  \n",
        "- Top similar words for `फेब्रुवारी (February)`: नोव्हेंबर (November) [0.007], मे (May) [0.023], मार्च (March) [0.026], एप्रिल (April) [0.028], जानेवारी (January) [0.035]  \n",
        "- Top similar words for `आंतरराष्ट्रीय (international)`: अफगाणिस्तान (Afghanistan) [0.011], स्कॉटलंड (Scotland) [0.012], बल्गेरिया (Bulgaria) [0.012], आयर्लंड (Ireland) [0.012]  \n",
        "- Top similar word for `असते (is/exists)`: `असतो (is/exists)` [0.064]  \n",
        "  - This is an **inflectional variant** of the same verb, reflecting Marathi’s rich morphology.  \n",
        "  - COALS embeddings naturally capture such variants because they appear in **similar syntactic and semantic contexts**.  \n",
        "  - Handling inflectional languages is challenging since the same base meaning can have many surface forms, but co-occurrence embeddings like COALS can **implicitly cluster these forms together**, improving semantic understanding (depending on the corpus).\n",
        "\n",
        "**Interpretation:**  \n",
        "- COALS embeddings capture **contextual similarity** rather than literal meaning.  \n",
        "- Words appearing in the same contexts are closer in vector space, even if they are not synonyms.  \n",
        "- Inflectional richness in Marathi is reflected in the embeddings, which helps model semantic patterns despite morphological complexity.  \n",
        "- This demonstrates the strength of co-occurrence-based embeddings in modeling semantic patterns in Marathi text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cd819fa-d0a8-4d96-b335-be4357254b02",
      "metadata": {
        "id": "8cd819fa-d0a8-4d96-b335-be4357254b02"
      },
      "source": [
        "### Task 4: Dense Word Embeddings via SVD\n",
        "\n",
        "**Objective:**  \n",
        "Generate dense word embeddings from the Pearson correlation matrix using Singular Value Decomposition (SVD). The goal is to reduce the high-dimensional 11,000-word vector space while retaining most of the semantic information.\n",
        "\n",
        "**Implementation:**  \n",
        "1. **Inspect Correlation Matrix:**  \n",
        "   - Shape: `(11,000 × 11,000)`  \n",
        "   - Checked min, max, and mean correlations to understand the co-occurrence patterns.  \n",
        "\n",
        "2. **Compute SVD:**  \n",
        "   - Applied SVD to decompose the correlation matrix into `U`, `S`, `Vt`.  \n",
        "   - Explored cumulative variance to determine optimal embedding dimensions:  \n",
        "     - 97% variance retained with 61 dimensions  \n",
        "     - 99% variance retained with 267 dimensions  \n",
        "   - This shows that the 11k-dimensional word space can be compressed significantly without losing most information.  \n",
        "\n",
        "3. **Compute Dense Embeddings:**  \n",
        "   - Dense vectors computed as `U[:, :embedding_dim] * sqrt(S[:embedding_dim])`.  \n",
        "   - Explored embeddings at dimensions 61, 100, and 300 to compare semantic similarity.\n",
        "\n",
        "**Observations:**  \n",
        "- **Comparison with COALS embeddings:**  \n",
        "  - Some nearest neighbors from dense embeddings align with COALS:  \n",
        "    - `फेब्रुवारी (February)` → `नोव्हेंबर (November)`  \n",
        "    - `आंतरराष्ट्रीय (International)` → `अफगाणिस्तान (Afghanistan)`, `स्कॉटलंड (Scotland)`  \n",
        "  - However, dense embeddings also reveal different context-related words not highlighted by COALS:\n",
        "    - 61-dim:  \n",
        "      - `आंतरराष्ट्रीय (International)` → `असोसिएट (Associate)`, `संघांचे (Of teams)`, `क्रिकेटचे (Of cricket)`, `देशांतर्गत (Domestically)`, `खेळाडूंची (Of players)`  \n",
        "      - `फेब्रुवारी (February)` → `नोव्हेंबर (November)`, `हिवाळा (Winter)`, `पावसाळा (Monsoon)`, `असतेमार्च (It's March)`, `हिवाळा (winter)`  \n",
        "    - 300-dim:  \n",
        "      - `आंतरराष्ट्रीय (International)` → `हाँग (Hong)`, `महिला (Women)`, `संघाविरुद्ध (Against the team)`, `कसोटी (Test)`, `विश्वचषकात (In World Cup)`  \n",
        "      - `फेब्रुवारी (February)` → `नोव्हेंबर (November)`, `हिवाळा (Winter)`, `पावसाळा (Monsoon)`, `अखेरपर्यंत (Until the end)`, `हंगाम (Season)`  \n",
        "\n",
        "- **Insights:**  \n",
        "  - Dense embeddings capture richer contextual information as dimensions increase, allowing related but not strictly synonymous words to appear as nearest neighbors.  \n",
        "  - Higher-dimensional embeddings (e.g., 300) reveal more nuanced semantic associations, enhancing potential downstream tasks like clustering, analogy reasoning, or semantic search.\n",
        "\n",
        "**Conclusion:**  \n",
        "- Dense embeddings via SVD complement sparse COALS embeddings.  \n",
        "- Lower dimensions retain core semantic similarity, while higher dimensions capture additional contextual and relational information.  \n",
        "- This demonstrates a trade-off between compact representation and semantic richness, guiding selection of embedding dimension based on application needs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "940543f1-8da0-4359-89d0-2b3e16cf9750",
      "metadata": {
        "id": "940543f1-8da0-4359-89d0-2b3e16cf9750"
      },
      "source": [
        "###  Summary: Why Retaining Negative Correlations Matters\n",
        "\n",
        ">- Keeping negative correlations in dense word embeddings lets us capture not just which words are similar, but also which ones are truly different, giving a richer sense of meaning compared to sparse embeddings.  \n",
        ">- This makes it easier to separate unrelated words, interpret the embeddings more clearly, and use them effectively for tasks like clustering or semantic search.  \n",
        ">- Comparing COALS and SVD-based embeddings shows that while both pick up some contextual patterns, dense embeddings go a step further, revealing deeper and more nuanced relationships between words.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48b0e401-19eb-4112-a747-29b3659a5974",
      "metadata": {
        "id": "48b0e401-19eb-4112-a747-29b3659a5974"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
